<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Programming | In Pursuit of Laziness]]></title>
  <link href="http://manishearth.github.io/blog/categories/programming/atom.xml" rel="self"/>
  <link href="http://manishearth.github.io/"/>
  <updated>2017-03-05T09:12:51-08:00</updated>
  <id>http://manishearth.github.io/</id>
  <author>
    <name><![CDATA[Manish Goregaokar]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[What Are Sum, Product, and Pi Types?]]></title>
    <link href="http://manishearth.github.io/blog/2017/03/04/what-are-sum-product-and-pi-types/"/>
    <updated>2017-03-04T18:52:00-08:00</updated>
    <id>http://manishearth.github.io/blog/2017/03/04/what-are-sum-product-and-pi-types</id>
    <content type="html"><![CDATA[<p><em>See also: <a href="https://tonyarcieri.com/a-quick-tour-of-rusts-type-system-part-1-sum-types-a-k-a-tagged-unions">Tony&rsquo;s post on the same topic</a></em></p>

<p>You often hear people saying &ldquo;Language X<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> has sum types&rdquo; or &ldquo;I wish language X had sum types&rdquo;<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>,
or &ldquo;Sum types are cool&rdquo;.</p>

<p>Much like fezzes and bow ties, sum types are indeed cool.</p>

<p><img class="center" src="/images/post/memes/sum-types-are-cool.jpg" width="400"></p>

<p>These days, I&rsquo;ve also seen people asking about &ldquo;Pi types&rdquo;, because of <a href="https://github.com/ticki/rfcs/blob/pi-types-2/text/0000-pi-types.md">this Rust RFC</a>.</p>

<p>But what does &ldquo;sum type&rdquo; mean? And why is it called that? And what, in the name of sanity, is
a Pi type?</p>

<p>Before I start, I&rsquo;ll mention that while I will be covering some type theory to explain the names
&ldquo;sum&rdquo; and &ldquo;product&rdquo;, you don&rsquo;t need to understand these names to use these things! Far too often
do people have trouble understanding relatively straightforward concepts in languages because
they have confusing names with confusing mathematical backgrounds<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>.</p>

<h2>So what&rsquo;s a sum type? (the no-type-theory version)</h2>

<p>In it&rsquo;s essence, a sum type is basically an &ldquo;or&rdquo; type. Let&rsquo;s first look at structs.</p>

<pre><code class="rust">struct Foo {
    x: bool,
    y: String,
}
</code></pre>

<p><code>Foo</code> is a <code>bool</code> AND a <code>String</code>. You need one of each to make one.
This is an &ldquo;and&rdquo; type, or a &ldquo;product&rdquo; type (I&rsquo;ll explain the name later).</p>

<p>So what would an &ldquo;or&rdquo; type be? It would be one where the value can be a
<code>bool</code> OR a <code>String</code>. You can achieve this with C++ with a union:</p>

<pre><code class="cpp">union Foo {
    bool x;
    string y;
}

foo.x = true; // set it to a bool
foo.y = "blah"; // set it to a string
</code></pre>

<p>However, this isn&rsquo;t <em>exactly</em> right, since the value doesn&rsquo;t store the information
of which variant it is. You could store <code>false</code> and the reader wouldn&rsquo;t know
if you had stored an empty <code>string</code> or a <code>false</code> <code>bool</code>.</p>

<p>There&rsquo;s a pattern called &ldquo;tagged union&rdquo; (or &ldquo;discriminated union&rdquo;) in C++ which bridges this gap.</p>

<pre><code class="cpp">union FooUnion {
    bool x;
    string y;
}

enum FooTag {
    BOOL, STRING
}

struct Foo {
    FooUnion data;
    FooTag tag;
}

// set it to a bool
foo.data.x = true;
foo.tag = BOOL;

// set it to a string
foo.data.y = "blah";
foo.tag = STRING;
</code></pre>

<p>Here, you manually set the tag when setting the value. C++ also has <code>std::variant</code> (or
<code>boost::variant</code>) that encapsulates this pattern with a better API.</p>

<p>While I&rsquo;m calling these &ldquo;or&rdquo; types here, the technical term for such types is &ldquo;sum&rdquo; types.
Other languages have built-in sum types.</p>

<p>Rust has them and calls them &ldquo;enums&rdquo;. These are a more generalized version of the
enums you see in other languages.</p>

<pre><code class="rust">enum Foo {
    Str(String),
    Bool(bool)
}

let foo = Foo::Bool(true);

// "pattern matching"
match foo {
    Str(s) =&gt; /* do something with string `s` */,
    Bool(b) =&gt; /* do something with bool `b` */,
}
</code></pre>

<p>Swift is similar, and also calls them enums
<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class='swift'><span class='line'><span class="k">enum</span> <span class="n">Foo</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">case</span> <span class="n">str</span><span class="p">(</span><span class="n">String</span><span class="p">)</span>
</span><span class='line'>    <span class="k">case</span> <span class="n">boolean</span><span class="p">(</span><span class="kt">bool</span><span class="p">)</span>
</span><span class='line'><span class="p">}</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span><span class="k">let</span> <span class="n">foo</span> <span class="o">=</span> <span class="n">Foo</span><span class="p">.</span><span class="n">boolean</span><span class="p">(</span><span class="nb">true</span><span class="p">);</span>
</span><span class='line'><span class="k">switch</span> <span class="n">foo</span> <span class="p">{</span>
</span><span class='line'>    <span class="k">case</span> <span class="p">.</span><span class="n">str</span><span class="p">(</span><span class="k">let</span> <span class="n">s</span><span class="p">)</span><span class="o">:</span>
</span><span class='line'>        <span class="c1">// do something with string &lt;code&gt;s&lt;/code&gt;</span>
</span><span class='line'>    <span class="k">case</span> <span class="p">.</span><span class="n">boolean</span><span class="p">(</span><span class="k">let</span> <span class="n">b</span><span class="p">)</span><span class="o">:</span>
</span><span class='line'>        <span class="c1">// do something with boolean &lt;code&gt;b&lt;/code&gt;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>You can fake these in Go using interfaces, as well. Typescript has built-in
unions which can be typechecked without any special effort, but you need
to add a tag (like in C++) to pattern match on them.</p>

<p>Of course, Haskell has them:</p>

<pre><code class="haskell">data Foo = B Bool | S String

-- define a function
doThing :: Foo -&gt; SomeReturnType
doThing (B b) = -- do something with boolean b
doThing (S s) = -- do something with string s

-- call it
doThing (S "blah")
doThing (B True)
</code></pre>

<p>One of the very common things that languages with sum types do is express nullability
as a sum type;</p>

<pre><code class="rust">// an Option is either "something", containing a type, or "nothing"
enum Option&lt;T&gt; {
    Some(T),
    None
}

let x = Some("hello");
match x {
    Some(s) =&gt; println!("{}", s),
    None =&gt; println!("no string for you"),
}
</code></pre>

<p>Generally, these languages have &ldquo;pattern matching&rdquo;, which is like a <code>switch</code>
statement on steroids. It lets you match on and destructure all kinds of things,
sum types being one of them. Usually, these are &ldquo;exhaustive&rdquo;, which means that
you are forced to handle all possible cases. In Rust, if you remove that <code>None</code>
branch, the program won&rsquo;t compile. So you&rsquo;re forced to deal with the none case,
<em>somehow</em>.</p>

<p>In general sum types are a pretty neat and powerful tool. Languages with them built-in
tend to make heavy use of them, almost as much as they use structs.</p>

<h2>Why do we call it a sum type?</h2>

<p><em>Here be (type theory) <a href="https://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools">dragons</a></em></p>

<p>Let&rsquo;s step back a bit and figure out what a type is.</p>

<p>It&rsquo;s really a restriction on the values allowed. It can have things like methods and whatnot
dangling off it, but that&rsquo;s not so important here.</p>

<p></p>

<p>In other words, it&rsquo;s a <a href="https://en.wikipedia.org/wiki/Set_(mathematics)">set</a>. A boolean is the set &#92;(\{\mathtt{true}, \mathtt{false}\}&#92;). An 8-bit unsigned integer
(<code>u8</code> in Rust) is the set &#92;(\{0, 1, 2, 3, &hellip;. 254, 255\}&#92;). A string is a set with
infinite elements, containing all possible valid strings<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>.</p>

<p>What&rsquo;s a struct? A struct with two fields contains every possible combination of elements from the two sets.</p>

<pre><code class="rust">struct Foo {
    x: bool,
    y: u8,
}
</code></pre>

<p>The set of possible values of <code>Foo</code> is</p>

<p>&#92;[\{(\mathtt{x}, \mathtt{y}): \mathtt{x} \in \mathtt{bool}, \mathtt y \in \mathtt{u8}\}&#92;]</p>

<p>(Read as &ldquo;The set of all &#92;((\mathtt{x}, \mathtt{y})&#92;) where &#92;(\tt x&#92;) is in &#92;(\mathtt{bool}&#92;) and &#92;(\tt y&#92;) is in &#92;(\mathtt{u8}&#92;)&rdquo;)</p>

<p>This is called a <em>Cartesian product</em>, and is often represented as &#92;(\tt Foo = bool \times u8&#92;).
An easy way to view this as a product is to count the possible values: The number of possible values
of <code>Foo</code> is the number of possible values of <code>bool</code> (2) <em>times</em> the number of possible values of <code>u8</code> (256).</p>

<p>A general struct would be a &ldquo;product&rdquo; of the types of each field, so something like</p>

<pre><code class="rust">struct Bar {
    x: bool,
    y: u8,
    z: bool,
    w: String
}
</code></pre>

<p>is &#92;(\mathtt{Bar = bool \times u8 \times bool \times String}&#92;)</p>

<p>This is why structs are called &ldquo;product types&rdquo;<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>.</p>

<p>You can probably guess what comes next &ndash; Rust/Swift enums are &ldquo;sum types&rdquo;, because they are the
<em>sum</em> of the two sets.</p>

<pre><code class="rust">enum Foo {
    Bool(bool),
    Integer(u8),
}
</code></pre>

<p>is a set of all values which are valid booleans, <em>and</em> all values which are valid integers. This
is a sum of sets, &#92;(\tt Foo = bool + u8&#92;). More accurately, it&rsquo;s a <em>disjoint union</em>, where if the input
sets have overlap, the overlap is &ldquo;discriminated&rdquo; out.</p>

<p>An example of this being a disjoint union is:</p>

<pre><code class="rust">enum Bar {
    Bool1(bool),
    Bool2(bool),
    Integer(u8).
}
</code></pre>

<p>This is not &#92;(\tt Bar = bool + bool + u8&#92;), because &#92;(\tt bool + bool = bool&#92;), (regular set addition doesn&rsquo;t duplicate the overlap).</p>

<p>Instead, it&rsquo;s something like</p>

<p>&#92;[\tt Bar = bool + otherbool + u8&#92;]</p>

<p>where &#92;(\tt otherbool&#92;) is also a set &#92;(\tt \{true, false\}&#92;),
except that these elements are <em>different</em> from those in &#92;(\tt bool&#92;). You can look at it as if</p>

<p>&#92;[\tt otherbool = \{true_2, false_2\}&#92;]</p>

<p>so that</p>

<p>&#92;[\mathtt{bool + otherbool} = \{\mathtt{true, false, true_2, false_2}\}&#92;]</p>

<p>For sum types, the number of possible values is the sum of the number of possible values of
each of its component types.</p>

<p>So, Rust/Swift enums are &ldquo;sum types&rdquo;.</p>

<p>You may often notice the terminology &ldquo;algebraic datatypes&rdquo; (ADT) being used, usually that&rsquo;s just
talking about sum and product types together &ndash; a language with ADTs will have both.</p>

<p>In fact, you can even have <em>exponential</em> types! The notation A<sup>B</sup> in set theory does mean something,
it&rsquo;s the set of all possible mappings from &#92;(B&#92;) to &#92;(A&#92;). The number of elements is &#92;(N_A^{N_B}&#92;). So
basically, the type of a function (which is a mapping) is an &ldquo;exponential&rdquo; type. You can also view it as
an iterated product type, a function from type <code>B</code> to <code>A</code> is really a struct like this:</p>

<pre><code class="rust">// the type
fn my_func(b: B) -&gt; A;

// is conceptually (each possible my_func can be written as an instance of)

struct my_func {
    b1: A, // value for first element in B
    b2: A, // value for second element in B
    b3: A,
    // ... 
}
</code></pre>

<p>given a value of the input <code>b</code>, the function will find the right field of <code>my_func</code> and return
the mapping. Since a struct is a product type, this is</p>

<p>&#92;[\mathtt{A}^{N_\mathtt{B}} = \tt A \times A \times A \times \dots&#92;]</p>

<p>making it an exponential type.</p>

<p><a href="http://strictlypositive.org/diff.pdf">You can even take <em>derivatives</em> of types!</a> (h/t Sam Tobin-Hochstadt for pointing this out to me)</p>

<p></p>

<h2>What, in the name of sanity, is a Pi type?</h2>

<p><img class="center" src="/images/post/memes/what-in-the-name-of-sanity.jpg" width="400"></p>

<p>It&rsquo;s essentially a form of dependent type. A dependent type is when your type
can depend on a value. An example of this is integer generics, where you
can do things like <code>Array&lt;bool, 5&gt;</code>, or <code>template&lt;unsigned int N, typename T&gt; Array&lt;T, N&gt; ...</code> (in C++).</p>

<p>The name comes from how a constructor for these types would look:</p>

<pre><code class="rust">// create an array of booleans from a given integer
// note that the *type signature* contains a type dependent on this integer.
// We are generic over multiple different array lengths here.

// I made up this syntax, this is _not_ from the Rust Pi type RFC
fn make_array(x: u8) -&gt; Array&lt;bool, x&gt; {
    // ...
}

// or
// (the proposed rust syntax)
fn make_array&lt;const x: u8&gt;() -&gt; Array&lt;bool, x&gt; {
   // ... 
}
</code></pre>

<p>What&rsquo;s the type of <code>make_array</code> here? It&rsquo;s a function which can accept any integer
and return a different type in each case. You can view it as a set of functions,
where each function corresponds to a different integer input. It&rsquo;s basically:</p>

<pre><code class="rust">struct make_array {
    make_array_0: fn() -&gt; Array&lt;bool, 0&gt;,
    make_array_1: fn() -&gt; Array&lt;bool, 1&gt;,
    make_array_2: fn() -&gt; Array&lt;bool, 2&gt;,
    make_array_3: fn() -&gt; Array&lt;bool, 3&gt;,
    make_array_4: fn() -&gt; Array&lt;bool, 4&gt;,
    make_array_5: fn() -&gt; Array&lt;bool, 5&gt;,
    // ... 
}
</code></pre>

<p>Given an input, the function chooses the right child function here, and calls it.</p>

<p></p>

<p>This is a struct, or a product type! But it&rsquo;s a product of an infinite number of types<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>.</p>

<p>We can look at it as</p>

<p>&#92;[\texttt{make_array} = \prod\limits_{x = 0}^\infty\left( \texttt{fn()} \mathtt\to \texttt{Array&lt;bool, x&gt;}\right)&#92;]</p>

<p>The usage of the &#92;(\Pi&#92;) symbol to denote an iterative product gives this the name &ldquo;Pi type&rdquo;.</p>

<p>In languages with lazy evaluation (like Haskell), there is no difference between having a function
that can give you a value, and actually having the value. So, the type of <code>make_array</code> is the type
of <code>Array&lt;bool, N&gt;</code> itself in languages with lazy evaluation.</p>

<p>There&rsquo;s also a notion of a &ldquo;sigma&rdquo; type, which is basically</p>

<p>&#92;[\sum\limits_{x = 0}^\infty \left(\texttt{fn()} \mathtt\to \texttt{Array&lt;bool, x&gt;}\right)&#92;]</p>

<p>With the Pi type, we had &ldquo;for all N we can
construct an array&rdquo;, with the sigma type we have &ldquo;there exists some N for which we can construct this array&rdquo;.
As you can expect, this type can be expressed with a possibly-infinite enum, and instances of this type
are basically instances of <code>Array&lt;bool, N&gt;</code> for some specific <code>N</code> where the <code>N</code> is only known at runtime.
(much like how regular sum types are instances of one amongst multiple types, where the exact type
is only known at runtime). <code>Vec&lt;bool&gt;</code> is conceptually similar to the sigma type <code>Array&lt;bool, ?&gt;</code>,
as is <code>&amp;[bool]</code>.</p>

<p></p>

<h2>Wrapping up</h2>

<p>Types are sets, and we can do set-theory things on them to make cooler types.</p>

<p>Let&rsquo;s try to avoid using confusing terminology, however. If Rust <em>does</em> get &ldquo;pi types&rdquo;,
let&rsquo;s just call them &ldquo;dependent types&rdquo; or &ldquo;const generics&rdquo; :)</p>

<p><em>Thanks to Zaki, Avi Weinstock, Corey Richardson, and Peter Atashian for reviewing drafts of this post.</em></p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Rust, Swift, <em>sort of</em> Typescript, and all the functional languages who had it before it was cool.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>Lookin&#8217; at you, Go.<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>Moooooooooooooooonads<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>Though you can argue that strings often have their length bounded by the pointer size of the platform, so it&rsquo;s still a finite set.<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>This even holds for zero-sized types, for more examples, check out <a href="http://chris-taylor.github.io/blog/2013/02/10/the-algebra-of-algebraic-data-types/">this blog post</a><a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
<li id="fn:6">
<p>Like with strings, in practice this would probably be bounded by the integer type chosen<a href="#fnref:6" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mitigating Underhandedness: Fuzzing Your Code]]></title>
    <link href="http://manishearth.github.io/blog/2017/03/02/mitigating-underhandedness-fuzzing-your-code/"/>
    <updated>2017-03-02T16:13:54-08:00</updated>
    <id>http://manishearth.github.io/blog/2017/03/02/mitigating-underhandedness-fuzzing-your-code</id>
    <content type="html"><![CDATA[<p><em>This may be part of a collaborative blog post series about underhanded Rust code. Or it may not. I invite you to write your own posts about underhanded code to make it so!</em></p>

<p>The <a href="https://underhanded.rs/blog/2017/02/28/extending-submission-deadline.en-US.html">submission deadline for the Underhanded Rust competition has been extended</a>, so
let&rsquo;s talk more about how to keep your code working and free from bugs/underhandedness!</p>

<p><a href="http://manishearth.github.io/blog/2017/01/21/mitigating-underhandedness-clippy/">Previously, we talked about Clippy</a>.</p>

<p>Now, really, underhanded bugs are just another form of bug. And how do we find bugs? We test!</p>

<p>We write unit tests. We run the code under Valgrind, ASan, MSan, UBSan, TSan, and any other sanitizer
we can get our hands on. Tests tests tests. More tests. Tests.</p>

<p>But, there&rsquo;s a problem here. You need to write <em>test cases</em> to make this work. These are inputs
fed to your code after which you check whatever invariants your code has. There&rsquo;s
no guarantee that the test cases you write will exercise all the code paths in your
program. This applies for sanitizers too, sanitizers are limited to testing the code paths
that your test cases hit.</p>

<p>Of course, you can use code coverage tools to ensure that all these code paths will be hit.
However, there&rsquo;s a conflict here &ndash; your code will have many code paths that are
<em>not supposed to be hit ever</em>. Things like redundant bounds checks, null checks, etc.
In Rust programs such code paths generally use panics.</p>

<p>Now, these code paths are never <em>supposed</em> to be hit, so they&rsquo;ll never show up in your
code coverage. But you don&rsquo;t have a guarantee that they can never be hit, short
of formally verifying your program. The only solution here is writing more test cases.</p>

<p>Aside from that, even ignoring those code paths, you still need to manually write
test cases for everything. For each possible code path in your code, if you want to
be sure.</p>

<p>Who wants to manually write a million test cases?</p>

<p><img class="center" src="/images/post/memes/aint-nobody.jpg" width="400"></p>

<p><img class="center" src="/images/post/memes/that-would-be-great.jpg" width="400"></p>

<p>Enter fuzzing. What fuzzing will do is feed your program random inputs, carefully watching the
codepaths being taken, and try to massage the inputs so that new, interesting (usually crashy)
codepaths are taken. You write tests for the fuzzer such that they can accept arbitrary input, and
the fuzzer will find cases where they crash or panic.</p>

<p>One of the most popular fuzzers out there is <a href="http://lcamtuf.coredump.cx/afl/">AFL</a>, which takes a binary and feeds it random
input. Rust <a href="https://github.com/rust-fuzz/afl.rs">has a library that you can use for running AFL</a>, however it currently needs
to be run via a Docker image or needs a recompilation of rustc, since it adds a custom LLVM pass.
We&rsquo;re working on making this step unnecessary.</p>

<p>However, as of a few weeks ago, we now have bindings for <a href="http://llvm.org/docs/LibFuzzer.html">libFuzzer</a>, which uses existing
instrumentation options built in to LLVM itself! libFuzzer works a bit differently; instead
of giving it a binary, you write a function in a special way and give it a library containing
that function, which it turns into a fuzzer binary. This is faster, since the fuzzer lives
inside the binary itself and it doesn&rsquo;t need to execute a new program each time.</p>

<p>Using libFuzzer in Rust is easy. Install <a href="https://github.com/rust-fuzz/cargo-fuzz"><code>cargo-fuzz</code></a>:</p>

<pre><code class="sh">$ cargo install cargo-fuzz
</code></pre>

<p>Now, within your crate, initialize the fuzz setup:</p>

<pre><code class="sh">$ cargo fuzz init
</code></pre>

<p>This will create a fuzzing crate in <code>fuzz/</code>, with a single &ldquo;fuzz target&rdquo;, <code>fuzzer_script_1</code>.
You can add more such targets with <code>cargo fuzz add name_of_target</code>. Fuzz targets are small libraries
with a single function in them; the function that will be called over and over again by the fuzzer.
It is up to you to fill in the body of this function, such that the program will crash or panic
if and only if something goes wrong.</p>

<p>For example, for the <code>unicode-segmentation</code> crate, <a href="https://github.com/Manishearth/unicode-segmentation/blob/99b3636ef6b4d96c05644403c1c2eccba2c5f5db/fuzz/fuzzers/equality.rs">one of the fuzz targets I wrote</a> just
takes the string, splits it by grapheme and word boundaries, recombines it, and then asserts that
the new string is the same.</p>

<pre><code class="rust">pub extern fn go(data: &amp;[u8]) {
    // we only deal with unicode input
    // bail early, *without panicking* if the input isn't utf8
    if let Ok(s) = str::from_utf8(data) {
        // split into graphemes, recollect
        let result = UnicodeSegmentation::graphemes(s, true).flat_map(|s| s.chars()).collect::&lt;String&gt;();
        // recollected string should be the same as the input, panic if not
        assert_eq!(s, result);

        // split into words, recollect
        let result = s.split_word_bounds().flat_map(|s| s.chars()).collect::&lt;String&gt;();
        // recollected string should be the same as the input, panic if not
        assert_eq!(s, result);
    }
}
</code></pre>

<p>The other targets ensure that the forward and reverse word/grapheme
iterators produce the same results. They all take the byte slice input, attempt to convert to UTF8
(silently failing  &ndash; NOT panicking &ndash; if not possible), and then use the string as an input
testcase.</p>

<p>Now, these targets will panic if the test fails, and the fuzzer will try and force that panic to
happen. But also, these targets put together exercise most of the API surface of the crate, so
the fuzzer may also find panics (or even segmentation faults!) in the crate itself. For example,
the <a href="https://github.com/servo/rust-url/blob/3e5541e51e02d8acb10a6ea8ab174ba1bc23ce41/fuzz/fuzzers/parse.rs#L10">fuzz target for rust-url</a> doesn&rsquo;t itself assert; all it does is try to parse the given
string. The fuzzer will try to get the URL parser to panic.</p>

<p>To run a fuzz script:</p>

<pre><code class="sh">$ cargo fuzz run fuzzer_script_1
</code></pre>

<p>This will start the fuzzer, running until it finds a crash or panic. It may also
find other things like inputs which make the code abnormally slow.</p>

<p>Fuzzing can find some interesting bugs. For example, the unicode-segmentation
fuzzers found <a href="https://github.com/unicode-rs/unicode-segmentation/issues/19">this bug</a>, where an emoji followed by <em>two</em> skin tone modifiers
isn&rsquo;t handled correctly. We&rsquo;d probably never have been able to come up with this testcase on our
own. But the fuzzer could find it!</p>

<p>The Rust Cap&#8217;n Proto crate ran cargo-fuzz and found <a href="https://dwrensha.github.io/capnproto-rust/2017/02/27/cargo-fuzz.html">a whole ton of bugs</a>. There
are more such examples <a href="https://github.com/rust-fuzz/cargo-fuzz#trophy-case">in the trophy case</a> (be sure to add any of your own findings
to the trophy case, too!)</p>

<p>cargo-fuzz is relatively new, so the API and behavior may still be tweaked a bit before 1.0.
But you can start taking it for a spin now, and finding bugs!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Clarifying Misconceptions About SHAttered]]></title>
    <link href="http://manishearth.github.io/blog/2017/02/26/clarifying-misconceptions-about-shattered/"/>
    <updated>2017-02-26T00:30:56-08:00</updated>
    <id>http://manishearth.github.io/blog/2017/02/26/clarifying-misconceptions-about-shattered</id>
    <content type="html"><![CDATA[<p>This week Google published a <a href="https://shattered.io/">SHA-1 collision</a>.</p>

<p>There&rsquo;s a lot of confusion about the implications of this. A lot of this is due to differences of
opinion on what exactly constitutes a &ldquo;new&rdquo; collision. I <a href="https://twitter.com/ManishEarth/status/835557328308969472">tweeted about this</a>. The webpage
for the attack itself is misleading, saying that the answer to &ldquo;Who is capable of mounting this attack?&rdquo;
is people with Google-esque resources. This depends on what exactly you mean by &ldquo;this attack&rdquo;.</p>

<p>So I&rsquo;m seeing a lot of &ldquo;oh well just another anti-milestone for SHA, doesn&rsquo;t affect anyone since its
still quite expensive to exploit&rdquo; reactions, as well as the opposite &ldquo;aaaaa everything is on fire&rdquo;
reaction. Both are wrong. It has practical implications for you even if you are certain that you
won&rsquo;t attract the ire of an entity with a lot of computational power. None of these implications,
however, are likely to be disastrous.</p>

<p>TLDR: Now <em>anyone</em>, without needing Google-esque resources,
can generate two colliding PDFs with arbitrary visual content in each.</p>

<p>(In fact, there&rsquo;s already <a href="http://alf.nu/SHA1">a PDF collision-generator</a> up where
you can upload two images and get a PDF with collisions in it)</p>

<h2>Okay, back up a bit. What&rsquo;s a hash? What&rsquo;s SHA-1?</h2>

<p>I explained this a bit in my older post about <a href="http://manishearth.github.io/blog/2016/03/05/exploring-zero-knowledge-proofs/">zero-knowledge-proofs</a>.</p>

<p>In essence, a hash function takes some data (usually of arbitrary size), and produces a value called
a <em>hash</em> (usually of fixed size). The function has some additional properties:</p>

<ul>
<li>In almost all cases, a small perturbation in the input will lead to a large perturbation in the hash</li>
<li>Given an input and its hash, it is computationally hard to find an alternate input producing the same hash</li>
<li>It&rsquo;s also hard to just find two inputs that has to the same value, though this is usually easier than the previous one</li>
</ul>


<p>when two inputs hash to the same value, this is called a collision. As mentioned, is easier to find
<em>a</em> collision, over finding a colliding alternate input for a known input.</p>

<p>SHA-1 is one such hash function. It&rsquo;s been known for a while that it&rsquo;s insecure, and the industry has
largely moved off of it, but it&rsquo;s still used,</p>

<h2>What did the researchers do?</h2>

<p>They found a hash collision for SHA-1. In essence, they found two strings, <code>A</code> and <code>B</code>, where
<code>SHA1(A) == SHA1(B)</code>.</p>

<p><em>However</em>, given the way SHA-1 works, this means that you can generate infinitely many other
such pairs of strings. And given the nature of the exact <code>A</code> and <code>B</code> they created, it is possible
to use this to create arbitrary colliding PDFs.</p>

<p>Basically, SHA-1 (and many other hash functions), operate on &ldquo;blocks&rdquo;. These are fixed-size chunks
of data, where the size is a property of the hash function. For SHA1 this is 512 bits.</p>

<p>The function starts off with an &ldquo;initial&rdquo; built-in hash. It takes the first block of your data and
this hash, and does some computation with the two to produce a new hash, which is its state after
the first block.</p>

<p>It will then take this hash and the second block, and run the same computations to produce
a newer hash, which is its state after the second block. This is repeated till all blocks have
been processed, and the final state is the result of the function.</p>

<p>There&rsquo;s an important thing to notice here. At each block, the only inputs are the block itself and the
hash of the string up to that block.</p>

<p>This means, if <code>A</code> and <code>B</code> are of a size that is a multiple of the block size, and <code>SHA1(A) == SHA1(B)</code>,
then <code>SHA1(A + C) == SHA1(B + C)</code>. This is because, when the hash function reaches <code>C</code>, the state will
be the same due to the hash collision, and after this point the next input blocks are identical in
both cases, so the final hash will be the same.</p>

<p>Now, while you might consider <code>A+C, B+C</code> to be the &ldquo;same collision&rdquo; as <code>A, B</code>, the implications
of this are different than just &ldquo;there is now one known pair of inputs that collide&rdquo;, since everyone
now has the ability to generate new colliding inputs by appending an arbitrary string to <code>A</code> and <code>B</code>.</p>

<p>Of course, these new collisions have the restriction that the strings will always start with <code>A</code> or
<code>B</code> and the suffixes will be identical. If you want to break this restriction, you will
have to devote expensive resources to finding a new collision, like Google did.</p>

<h2>How does this let us generate arbitrary colliding PDFs?</h2>

<p>So this exploit actually uses features of the JPEG format to work. It was done in
a PDF format since JPEGs often get compressed when sent around the Internet. However,
since both A and B start a partial PDF document, they can only be used to generate colliding
PDFs, not JPEGs.</p>

<p>I&rsquo;m going to first sketch out a simplified example of what this is doing, using a hypothetical
pseudocode-y file format. The researchers found a collision between the strings:</p>

<ul>
<li>A: <code>&lt;header data&gt; COMMENT(&lt;nonce for A&gt;) DISPLAY IMAGE 1</code></li>
<li>B: <code>&lt;header data&gt; COMMENT(&lt;nonce for B&gt;) DISPLAY IMAGE 2</code></li>
</ul>


<p>Here, <code>&lt;header data&gt;</code> is whatever is necessary to make the format work, and the &ldquo;nonce&#8221;s are
strings that make <code>A</code> and <code>B</code> have the same hash. Finding these nonces is where
the computational power is required, since you basically have to brute-force a solution.</p>

<p>Now, to both these strings, they append a suffix C: <code>IMAGE 1(&lt;data for image 1&gt;) IMAGE 2(&lt;data for image 2&gt;)</code>.
This creates two complete documents. Both of the documents contain both images, but each one is instructed
to display a different one. Note that since <code>SHA1(A) == SHA1(B)</code>, <code>SHA1(A + C) = SHA1(B + C)</code>, so these
final documents have the same hash.</p>

<p>The contents of <code>C</code> don&rsquo;t affect the collision at all. So, we can insert any two images in <code>C</code>, to create
our own personal pair of colliding PDFs.</p>

<p>The actual technique used is similar to this, and it relies on JPEG comment fields. They have found
a collision between two strings that look like:</p>

<pre><code class="text">pdf header data                       | String A
begin embedded image                  |  
    jpg header data                   |
    declare jpg comment of length N   |
    random nonce of length N          | (comment ends here) 
                                     ---
    image 1, length L                 | String C
    jpg EOF byte (2 bytes)            |
    image 2                           |
end embedded image                    |

and

pdf header data                       | String B
begin embedded image                  |
    jpg header data                   |
    declare jpg comment of length M   |
    random nonce of length M-L-2      |
                                     ---
    image 1, length L                 | String C
    jpg EOF marker (2 bytes)          | (comment ends here)
    image 2                           |
end embedded image                    |
</code></pre>

<p>By playing with the nonces, they managed to generate a collision between <code>A</code> and <code>B</code>. In the first
pdf, the embedded image has a comment containing only the nonce. Once the JPEG reader gets past that
comment, it sees the first image, displays it, and then sees the end-of-file marker and decides to
stop. Since the PDF format doesn&rsquo;t try to interpret the image itself, the PDF format won&rsquo;t be
boggled by the fact that there&rsquo;s some extra garbage data after the JPEG EOF marker. It
simply takes all the data between the &ldquo;begin embedded image&rdquo; and &ldquo;end embedded image&rdquo; blocks,
and passes it to the JPEG decoder. The JPEG decoder itself stops after it sees the end of file
marker, and doesn&rsquo;t get to the extra data for the second image.</p>

<p>In the second pdf, the jpg comment is longer, and subsumes the first image (as well as the EOF marker)
Thus, the JPEG decoder directly gets to the second image, which it displays.</p>

<p>Since the actual images are not part of the original collision (A and B), you can substitute any pair
of jpeg images there, with some length restrictions.</p>

<h2>What are the implications?</h2>

<p>This does mean that you should not trust the integrity of a PDF when all you have
to go on is its SHA-1 hash. Use a better hash. <em>Anyone can generate these colliding PDFs
now.</em></p>

<p>Fortunately, since all such PDFs will have the same prefix A or B, you can detect when
such a deception is being carried out.</p>

<p>Don&rsquo;t check colliding PDFs into SVN. <a href="https://bugs.webkit.org/show_bug.cgi?id=168774#c27">Things break</a>.</p>

<p>In some cases it is possible to use the PDF collision in other formats. For example,
<a href="https://mobile.twitter.com/arw/status/834883944898125824">it can be used to create colliding HTML documents</a>. I think it can be used to colide
ZIP files too.</p>

<p>Outside the world of complex file formats, little has changed. It&rsquo;s still a bad idea to use SHA-1.
It&rsquo;s still possible for people to generate entirely new collisions like Google did, though this
needs a lot of resources. It&rsquo;s possible that someone with resources has already generated such a
&ldquo;universal-key collision&rdquo; for some other file format<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> and will use it on you, but this was
equally possible before Google published their attack.</p>

<p>This does not make it easier to collide with arbitrary hashes &ndash; if someone else
has uploaded a document with a hash, and you trust them to not be playing any tricks,
an attacker won&rsquo;t be able to generate a colliding document for this without immense
resources. The attack only works when the attacker has control over the initial document;
e.g. in a bait-and-switch-like attack where the attacker uploads document A, you read and verify it
and broadcast your trust in document A with hash <code>SHA(A)</code>, and then the attacker switches it with
document B.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Google&rsquo;s specific collision was designed to be a &ldquo;universal key&rdquo;, since A and B are designed to have the image-switching mechanism built into it. Some other collision may not be like this; it could just be a collision of two images (or whatever) with no such switching mechanism. It takes about the same effort to do either of these, however, so if you have a file format that can be exploited to create a switching mechanism, it would always make more sense to build one into any collision you look for.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mitigating Underhandedness: Clippy!]]></title>
    <link href="http://manishearth.github.io/blog/2017/01/21/mitigating-underhandedness-clippy/"/>
    <updated>2017-01-21T15:22:16-08:00</updated>
    <id>http://manishearth.github.io/blog/2017/01/21/mitigating-underhandedness-clippy</id>
    <content type="html"><![CDATA[<p><em>This may be part of a collaborative blog post series about underhanded Rust code. Or it may not. I invite you to write your own posts about underhanded code to make it so!</em></p>

<p>Last month we opened up <a href="https://underhanded.rs/blog/2016/12/15/underhanded-rust.en-US.html">The Underhanded Rust competition</a>. This contest is about
writing seemingly-innocuous malicious code; code that is deliberately written to do some harm,
but will pass a typical code review.</p>

<p>It is inspired by the <a href="http://www.underhanded-c.org">Underhanded C</a> contest. Most of the underhanded C submissions have to do
with hidden buffer overflows, pointer arithmetic fails, or misuse of C macros; and these problems
largely don&rsquo;t occur in Rust programs. However, the ability to layer abstractions on each other does
open up new avenues to introducing underhandedness by relying on sufficiently confusing abstraction
sandwiches. There are probably other interesting avenues. Overall, I&rsquo;m pretty excited to see what
kind of underhandedness folks come up with!</p>

<p>Of course, underhandedness is not just about fun and games; we should be hardening our code against
this kind of thing. Even if you trust your fellow programmers. Even if <em>you</em> are the sole programmer and you trust yourself.
After all, <a href="https://github.com/Gankro/thesis/blob/master/thesis.pdf">you can&rsquo;t spell Trust without Rust</a>; and Rust is indeed about trust. Specifically,
Rust is about trusting <em>nobody</em>. Not even yourself.</p>

<p><img src="/images/post/memes/trust-nobody.jpg" width="300"></p>

<p>Rust protects you from your own mistakes when it comes to memory management. But we
should be worried about other kinds of mistakes, too. Many of the techniques used in underhanded
programming involve sleights of hand that could just as well be introduced in the code by accident, causing bugs.
Not memory safety bugs (in Rust), but still, bugs. The existence of these sleights of hand is great for
that very common situation
<a href="https://underhanded.rs/blog/2016/12/15/underhanded-rust.en-US.html#prize">when you are feeling severely under-plushied and must win a competition to replenish your supply</a>
but we really don&rsquo;t want these creeping into real-world code, either by accident or intentionally.</p>

<hr />

<p>Allow me to take a moment out of your busy underhanded-submission-writing schedules to talk to you about
our Lord and Savior <a href="http://github.com/manishearth/rust-clippy/">Clippy</a>.</p>

<p>Clippy is for those of you who have become desensitized to the constant whining of the Rust compiler
and need a higher dosage of whininess to be kept on their toes. Clippy is for those perfectionists
amongst you who want to know every minute thing wrong with their code so that they can fix it.
But really, Clippy is for everyone.</p>

<p>Clippy is simply a large repository of lints. As of the time of writing this post, there are
<a href="https://github.com/manishearth/rust-clippy/#lints">183 lints</a> in it, though not all of them are enabled by default. These use the regular Rust lint
system so you can pick and choose the ones you need via <code>#[allow(lint_name)]</code> and
<code>#[warn(lint_name)]</code>. These lints cover a wide range of functions:</p>

<ul>
<li>Improving readability of the code (though <a href="https://github.com/rust-lang-nursery/rustfmt/">rustfmt</a> is the main tool you should use for this)</li>
<li>Helping make the code more compact by reducing unnecessary things (my absolute favorite is <a href="https://github.com/Manishearth/rust-clippy/wiki#needless_lifetimes">needless_lifetimes</a>)</li>
<li>Helping make the code more idiomatic</li>
<li>Making sure you don&rsquo;t do things that you&rsquo;re not supposed to</li>
<li>Catching mistakes and cases where the code may not work as expected</li>
</ul>


<p>The last two really are the ones which help with underhanded code. Just to give an example,
we have lints like:</p>

<ul>
<li><a href="https://github.com/Manishearth/rust-clippy/wiki#cmp_nan">cmp_nan</a>, which disallows things like <code>x == NaN</code></li>
<li><a href="https://github.com/Manishearth/rust-clippy/wiki#clone_double_ref">clone_double_ref</a>, which disallows calling <code>.clone()</code> on double-references (<code>&amp;&amp;T</code>), since that&rsquo;s a straightforward copy and you probably meant to do something like <code>(*x).clone()</code></li>
<li><a href="https://github.com/Manishearth/rust-clippy/wiki#for_loop_over_option">for_loop_over_option</a>: <code>Option&lt;T&gt;</code> is iterable, and while this is useful when composing iterators, directly iterating over an option is usually an indication of a mistake.</li>
<li><a href="https://github.com/Manishearth/rust-clippy/wiki#match_same_arms">match_same_arms</a>, which checks for identical match arm bodies (strong indication of a typo)</li>
<li><a href="https://github.com/Manishearth/rust-clippy/wiki#suspicious_assignment_formatting">suspicious_assignment_formatting</a>, which checks for possible typos with the <code>+=</code> and <code>-=</code> operators</li>
<li><a href="https://github.com/Manishearth/rust-clippy/wiki#unused_io_amount">unused_io_amount</a>, which ensures that you don&rsquo;t forget that some I/O APIs may not write all bytes in the span of a single call</li>
</ul>


<p>These catch many of the gotchas that might crop up in Rust code. In fact,
I based <a href="https://www.reddit.com/r/rust/comments/3hb0wm/underhanded_rust_contest/cu5yuhr/">my solution of an older, more informal Underhanded Rust contest</a> on one of these.</p>

<h2>Usage</h2>

<p>Clippy is still nightly-only. We hook straight into the compiler&rsquo;s guts to obtain
the information we need, and like most internal compiler APIs, this is completely unstable. This
does mean that you usually need a latest or near-latest nightly for clippy to work, and there will
be times when it won&rsquo;t compile while we&rsquo;re working to update it.</p>

<p>There is a plan to ship clippy as an optional component of rustc releases, which will fix all of
these issues (yay!).</p>

<p>But, for now, you can use clippy via:</p>

<pre><code class="sh">rustup install nightly
# +nightly not necessary if nightly is your default toolchain
cargo +nightly install clippy
# in your project folder
cargo +nightly clippy
</code></pre>

<p>If you&rsquo;re going to be making it part of the development procedures of a crate
you maintain, you can also <a href="https://github.com/manishearth/rust-clippy/#optional-dependency">make it an optional dependency</a>.</p>

<p>If you&rsquo;re on windows, there&rsquo;s currently a rustup/cargo <a href="https://github.com/rust-lang-nursery/rustup.rs/issues/876">bug</a> where you may have to add
the rustc libs path in your <code>PATH</code> for <code>cargo clippy</code> to work.</p>

<p>There&rsquo;s an experimental project called <a href="https://github.com/killercup/rustfix">rustfix</a> which can automatically apply suggestions from
clippy and rustc to your code. This may help in clippy-izing a large codebase, but it may
also eat your code and/or laundry, so beware.</p>

<h2>Contributing</h2>

<p>There&rsquo;s a <em>lot</em> of work that can be done on clippy. A hundred and eighty lints is just
a start, there are <a href="https://github.com/manishearth/rust-clippy/issues">hundreds more lint ideas filed on the issue tracker</a>. We&rsquo;re
willing to mentor anyone who wants to get involved; and have
<a href="https://github.com/manishearth/rust-clippy/issues?q=is%3Aissue+is%3Aopen+label%3AE-easy">specially tagged &ldquo;easy&rdquo; issues</a> for folks new to compiler internals. In general,
contributing to clippy is a great way to gain an understanding of compiler internals
if you want to contribute to the compiler itself.</p>

<p>If you don&rsquo;t want to write code for clippy, you can also run it on random crates,
open pull requests with fixes, and file bugs on clippy for any false positives that appear.</p>

<p>There are more tips about contributing in <a href="https://github.com/Manishearth/rust-clippy/blob/master/CONTRIBUTING.md">our CONTRIBUTING.md</a>.</p>

<hr />

<p>I hope this helps reduce mistakes and underhandedness in your code!</p>

<p>..unless you&rsquo;re writing code for the Underhanded Rust competition. In that case, underhand away!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Breaking Our Latin-1 Assumptions]]></title>
    <link href="http://manishearth.github.io/blog/2017/01/15/breaking-our-latin-1-assumptions/"/>
    <updated>2017-01-15T13:34:16-08:00</updated>
    <id>http://manishearth.github.io/blog/2017/01/15/breaking-our-latin-1-assumptions</id>
    <content type="html"><![CDATA[<p>So in my <a href="http://manishearth.github.io/blog/2017/01/14/stop-ascribing-meaning-to-unicode-code-points">previous post</a> I explored a specific (wrong) assumption that programmers
tend to make about the nature of code points and text.</p>

<p>I was asked multiple times about other assumptions we tend to make. There are a lot. Most
Latin-based scripts are simple, but most programmers spend their time dealing with Latin
text so these complexities never come up.</p>

<p>I thought it would be useful to share my personal list of
<a href="https://twitter.com/ManishEarth/status/810582690906931200">scripts that break our Latin-1 assumptions</a>. This is a list I mentally check against
whenever I am attempting to reason about text. I check if I&rsquo;m making any assumptions that
break in these scripts. <em>Most</em> of these concepts are independent of Unicode; so any program
would have to deal with this regardless of encoding.</p>

<p>I again recommend going through <a href="https://eev.ee/blog/2015/09/12/dark-corners-of-unicode/">eevee&rsquo;s post</a>, since it covers many related issues.
<a href="https://github.com/jagracey/Awesome-Unicode">Awesome-Unicode</a> also has a lot of random tidbits about Unicode.</p>

<p>Anyway, here&rsquo;s the list. Note that a lot of the concepts here exist in scripts other than the
ones listed, these are just the scripts <em>I</em> use for comparing.</p>

<h2>Arabic / Hebrew</h2>

<p>Both Arabic and Hebrew are RTL scripts; they read right-to-left. This may even affect how
a page is laid out, see the <a href="https://he.wikipedia.org/wiki/%D7%A2%D7%9E%D7%95%D7%93_%D7%A8%D7%90%D7%A9%D7%99">Hebrew Wikipedia</a>.</p>

<p>They both have a concept of letters changing how they look depending on where they are in the word.
Hebrew has the &ldquo;sofit&rdquo; letters, which use separate code points. For example, Kaf (כ) should be typed
as ך at the end of a word. Greek has something similar with the sigma.</p>

<p>In Arabic, the letters can have up to four different forms, depending on whether they start a word,
end a word, are inside a word, or are used by themselves. These forms can look very different. They
don&rsquo;t use separate code points for this; however. You can see a list of these forms <a href="https://en.wikipedia.org/wiki/Arabic_alphabet#Table_of_basic_letters">here</a></p>

<p>As I mentioned in the last post, U+FDFD (﷽), a ligature representing the Basamala,
is also a character that breaks a lot of assumptions.</p>

<h2>Indic scripts</h2>

<p>Indic scripts are <em>abugidas</em>, where you have consonants with vowel modifiers. For example, क is
&ldquo;kə&rdquo;, where the upside down &ldquo;e&rdquo; is a schwa, something like an &ldquo;uh&rdquo; vowel sound. You can change the
vowel by adding a diacritic (e.g <code>ा</code>); getting things like का (&ldquo;kaa&rdquo;) को (&ldquo;koh&rdquo;) कू (&ldquo;koo&rdquo;).</p>

<p>You can also mash together consonants to create consonant clusters. The &ldquo;virama&rdquo; is a vowel-killer
symbol that removes the inherent schwa vowel. So, <code>क</code> + <code>्</code> becomes <code>क्</code>. This sound itself is
unpronounceable since क is a stop consonant (vowel-killed consonants can be pronounced for nasal and some other
consonants though), but you can combine it with another consonant, as <code>क्</code> + <code>र</code> (&ldquo;rə&rdquo;), to get <code>क्र</code>
(&ldquo;krə&rdquo;). Consonants can be strung up infinitely, and you can stick one or more vowel diacritics
after that. Usually, you won&rsquo;t see more than two consonants in a cluster, but larger ones are not
uncommon in Sanskrit (or when writing down some onomatopoeia). They may not get rendered as single
glyphs, depending on the font.</p>

<p>One thing that crops up is that there&rsquo;s no unambiguous concept of a letter here. There
is a concept of an &ldquo;akshara&rdquo;, which basically includes the vowel diacritics, and
depending on who you talk to may also include consonant clusters. Often things are
clusters an akshara depending on whether they&rsquo;re drawn with an explicit virama
or form a single glyph.</p>

<p>In general the nature of the virama as a two-way combining character in Unicode is pretty new.</p>

<h2>Hangul</h2>

<p>Korean does its own fun thing when it comes to conjoining characters. Hangul has a concept
of a &ldquo;syllable block&rdquo;, which is basically a letter. It&rsquo;s made up of a leading consonant,
medial vowel, and an optional tail consonant. &#x1100;&#x1161;&#x11A8; is an example of
such a syllable block, and it can be typed as &#x1100; + &#x1161; + &#x11A8;. It can
also be typed as &#xAC01;, which is a &ldquo;precomposed form&rdquo; (and a single code point).</p>

<p>These characters are examples of combining characters with very specific combining rules. Unlike
accents or other diacritics, these combining characters will combine with the surrounding characters
only when the surrounding characters form an L-V-T or L-V syllable block.</p>

<p>As I mentioned in my previous post, apparently syllable blocks with more (adjacent) Ls, Vs, and Ts are
also valid and used in Old Korean, so the grapheme segmentation algorithm in Unicode considers
&ldquo;ᄀᄀᄀ&#x1100;&#x1161;&#x11A8;ᆨᆨ&rdquo; to be a single grapheme (<a href="http://www.unicode.org/reports/tr29/#Hangul_Syllable_Boundary_Determination">it explicitly mentions this</a>).
I&rsquo;m not aware of any fonts which render these as a single syllable block, or if that&rsquo;s even
a valid thing to do.</p>

<h2>Han scripts</h2>

<p>So Chinese (Hanzi), Japanese (Kanji<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>), Korean (Hanja<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>), and Vietnamese (Hán tự, along with Chữ
Nôm <sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>) all share glyphs, collectively called &ldquo;Han characters&rdquo; (or CJK characters<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>). These
languages at some point in their history borrowed the Chinese writing system, and made their own
changes to it to tailor to their needs.</p>

<p>Now, the Han characters are ideographs. This is not a phonetic script; individual characters
represent words. The word/idea they represent is not always consistent across languages. The
pronounciation is usually different too. Sometimes, the glyph is drawn slightly differently based on
the language used. There are around 80,000 Han ideographs in Unicode right now.</p>

<p>The concept of ideographs itself breaks some of our Latin-1 assumptions. For example, how
do you define Levenshtein edit distance for text using Han ideographs? The straight answer is that
you can&rsquo;t, though if you step back and decide <em>why</em> you need edit distance you might be able
to find a workaround. For example, if you need it to detect typos, the user&rsquo;s input method
may help. If it&rsquo;s based on pinyin or bopomofo, you might be able to reverse-convert to the
phonetic script, apply edit distance in that space, and convert back. Or not. I only maintain
an idle curiosity in these scripts and don&rsquo;t actually use them, so I&rsquo;m not sure how well this would
work.</p>

<p>The concept of halfwidth character is a quirk that breaks some assumptions.</p>

<p>In the space of Unicode in particular, all of these scripts are represented by a single set of
ideographs. This is known as &ldquo;Han unification&rdquo;. This is a pretty controversial issue, but the
end result is that rendering may sometimes be dependent on the language of the text, which
e.g. in HTML you set with a <code>&lt;span lang=whatever&gt;</code>. <a href="https://en.wikipedia.org/wiki/Han_unification#Examples_of_language-dependent_glyphs">The wiki page</a> has some examples of
encoding-dependent characters.</p>

<p>Unicode also has a concept of variation selector, which is a code point that can be used to
select between variations for a code point that has multiple ways of being drawn. These
do get used in Han scripts.</p>

<p>While this doesn&rsquo;t affect rendering, Unicode, as a system for <em>describing</em> text,
also has a concept of interlinear annotation characters. These are used to represent
<a href="https://en.wikipedia.org/wiki/Ruby_character">furigana / ruby</a>. Fonts don&rsquo;t render this, but it&rsquo;s useful if you want to represent
text that uses ruby. Similarly, there are <a href="https://en.wikipedia.org/wiki/Chinese_character_description_languages#Ideographic_Description_Sequences">ideographic description sequences</a> which
can be used to &ldquo;build up&rdquo; glyphs from smaller ones when the glyph can&rsquo;t be encoded in
Unicode. These, too, are not to be rendered, but can be used when you want to describe
the existence of a character like <a href="https://en.wikipedia.org/wiki/Biangbiang_noodles#Chinese_character_for_bi.C3.A1ng">biáng</a>. These are not things a programmer
needs to worry about; I just find them interesting and couldn&rsquo;t resist mentioning them :)</p>

<p>Japanese speakers haven&rsquo;t completely moved to Unicode; there are a lot of things out there
using Shift-JIS, and IIRC there are valid reasons for that (perhaps Han unification?). This
is another thing you may have to consider.</p>

<p>Finally, these scripts are often written <em>vertically</em>, top-down. <a href="https://en.wikipedia.org/wiki/Mongolian_script">Mongolian</a>, while
not being a Han script, is written vertically sideways, which is pretty unique. The
CSS <a href="https://drafts.csswg.org/css-writing-modes/">writing modes</a> spec introduces various concepts related to this, though that&rsquo;s mostly in the
context of the Web.</p>

<h2>Thai / Khmer / Burmese / Lao</h2>

<p>These scripts don&rsquo;t use spaces to split words. Instead, they have rules for what kinds of sequences
of characters start and end a word. This can be determined programmatically, however IIRC the
Unicode spec does not attempt to deal with this. There are libraries you can use here instead.</p>

<h2>Latin scripts themselves!</h2>

<p>Turkish is a latin-based script. But it has a quirk: The uppercase of &ldquo;i&rdquo; is
a dotted &ldquo;İ&rdquo;, and the lowercase of &ldquo;I&rdquo; is &ldquo;ı&rdquo;. If doing case-based operations, try to use
a Unicode-aware library, and try to provide the locale if possible.</p>

<p>Also, not all code points have a single-codepoint uppercase version. The eszett (ß) capitalizes
to &ldquo;SS&rdquo;. There&rsquo;s also the &ldquo;capital&rdquo; eszett ẞ, but its usage seems to vary and I&rsquo;m not exactly
sure how it interacts here.</p>

<p>While Latin-1 uses precomposed characters, Unicode also introduces ways to specify the same
characters via combining diacritics. Treating these the same involves using the normalization
algorithms (NFC/NFD).</p>

<h2>Emoji</h2>

<p>Well, not a script<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>. But emoji is weird enough that it breaks many of our assumptions. The
scripts above cover most of these, but it&rsquo;s sometimes easier to think of them
in the context of emoji.</p>

<p>The main thing with emoji is that you can use a zero-width-joiner character to glue emoji together.</p>

<p>For example, the family emoji 👩‍👩‍👧‍👦 (may not render for you) is made by using the woman/man/girl/boy
emoji and gluing them together with ZWJs. You can see its decomposition in <a href="https://r12a.github.io/uniview/?charlist=%F0%9F%91%A9%E2%80%8D%F0%9F%91%A9%E2%80%8D%F0%9F%91%A7%E2%80%8D%F0%9F%91%A6">uniview</a>.</p>

<p>There are more sequences like this, which you can see in the <a href="http://unicode.org/Public/emoji/4.0/emoji-zwj-sequences.txt">emoji-zwj-sequences</a> file. For
example, MAN + ZWJ + COOK will give a male cook emoji (font support is sketchy).
Similarly, SWIMMER + ZWJ + FEMALE SIGN is a female swimmer. You have both sequences of
the form &ldquo;gendered person + zwj + thing&rdquo;, and &ldquo;emoji containing human + zwj + gender&rdquo;,
IIRC due to legacy issues<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup></p>

<p>There are also <a href="http://www.unicode.org/reports/tr51/#Diversity">modifier characters</a> that let you change the skin tone of an emoji that
contains a human (or human body part, like the hand-gesture emojis) in it.</p>

<p>Finally, the flag emoji are pretty special snowflakes. For example, 🇪🇸 is the Spanish
flag. It&rsquo;s made up of <a href="https://r12a.github.io/uniview/?charlist=%F0%9F%87%AA%F0%9F%87%B8">two regional indicator characters for &ldquo;E&rdquo; and &ldquo;S&rdquo;</a>.</p>

<p>Unicode didn&rsquo;t want to deal with adding new flags each time a new country or territory pops up. Nor
did they want to get into the tricky business of determining what a country <em>is</em>, for example
when dealing with disputed territories. So instead, they just defined these regional indicator
symbols. Fonts are supposed to take pairs of RI symbols<sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup> and map the country code to a flag.
This mapping is up to them, so it&rsquo;s totally valid for a font to render a regional indicator
pair &ldquo;E&rdquo; + &ldquo;S&rdquo; as something other than the flag of Spain. On some Chinese systems, for example,
the flag for Taiwan (🇹🇼) may not render.</p>

<hr />

<p>I hightly recommend comparing against this relatively small list of scripts the next time you
are writing code that does heavy manipulation of user-provided strings.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Supplemented (but not replaced) by the Hiragana and Katakana phonetic scripts. In widespread use.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>Replaced by Hangul in modern usage<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>Replaced by chữ quốc ngữ in modern usage, which is based on the Latin alphabet<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>&ldquo;CJK&rdquo; (Chinese-Japanese-Korean) is probably more accurate here, though it probably should include &ldquo;V&rdquo; for Vietnamese too. Not all of these ideographs come from Han; the other scripts invented some of their own. See: Kokuji, Gukja, Chữ Nôm.<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>Back in <em>my</em> day we painstakingly typed actual real words on numeric phone keypads, while trudging to 🏫 in three feet of ❄️️, and it was uphill both ways, and we weren&rsquo;t even <em>allowed</em> 📱s in 🏫. Get off my lawn!<a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
<li id="fn:6">
<p>We previously had individual code points for professions and stuff and they decided to switch over to using existing object emoji with combiners instead of inventing new profession emoji all the time<a href="#fnref:6" rev="footnote">&#8617;</a></p></li>
<li id="fn:7">
<p>676 countries should be enough for anybody<a href="#fnref:7" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
</feed>

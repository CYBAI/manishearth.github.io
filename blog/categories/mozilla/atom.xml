<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Mozilla | In Pursuit of Laziness]]></title>
  <link href="http://manishearth.github.io/blog/categories/mozilla/atom.xml" rel="self"/>
  <link href="http://manishearth.github.io/"/>
  <updated>2018-02-16T02:53:16+00:00</updated>
  <id>http://manishearth.github.io/</id>
  <author>
    <name><![CDATA[Manish Goregaokar]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[A Rough Proposal for Sum Types in Go]]></title>
    <link href="http://manishearth.github.io/blog/2018/02/01/a-rough-proposal-for-sum-types-in-go/"/>
    <updated>2018-02-01T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/02/01/a-rough-proposal-for-sum-types-in-go</id>
    <content type="html"><![CDATA[<p>Sum types are pretty cool. Just like how a struct is basically &ldquo;This contains one of these <em>and</em> one of these&rdquo;,
a sum type is &ldquo;This contains one of these <em>or</em> one of these&rdquo;.</p>

<p>So for example, the following sum type in Rust:</p>

<pre><code class="rust">enum Foo {
    Stringy(String),
    Numerical(u32)
}
</code></pre>

<p>or Swift:</p>

<pre><code class="swift">enum Foo {
    case stringy(String),
    case numerical(Int)
}
</code></pre>

<p>would be one where it&rsquo;s either <code>Foo::Stringy</code> (<code>Foo::stringy</code> for swift), containing a <code>String</code>,
<em>or</em> <code>Foo::Numerical</code>, containing an integer.</p>

<p>This can be pretty useful. For example, messages between threads are often of a &ldquo;this or that or that or that&rdquo;
form.</p>

<p>The nice thing is, matching (switching) on these enums is usually <em>exhaustive</em> &ndash; you must list all
the cases (or include a default arm) for your code to compile. This leads to a useful component
of type safety &ndash; if you add a message to your message passing system, you&rsquo;ll know where to update it.</p>

<p>Go doesn&rsquo;t have these. Go <em>does</em> have interfaces, which are dynamically dispatched. The drawback here
is that you do not get the exhaustiveness condition, and consumers of your library can even add further
cases. (And, of course, dynamic dispatch can be slow). You <em>can</em> get exhaustiveness in Go with <a href="https://github.com/haya14busa/gosum">external tools</a>,
but it&rsquo;s preferable to have such things in the language IMO.</p>

<p>Many years ago when I was learning Go I wrote a <a href="http://inpursuitoflaziness.blogspot.in/2015/02/thoughts-of-rustacean-learning-go.html">blog post</a> about what I liked and disliked
as a Rustacean learning Go. Since then, I&rsquo;ve spent a lot more time with Go, and I&rsquo;ve learned to like each Go design decision that I initially
disliked, <em>except</em> for the lack of sum types. Most of my issues arose from &ldquo;trying to program Rust in Go&rdquo;,
i.e. using idioms that are natural to Rust (or other languages I&rsquo;d used previously). Once I got used to the
programming style, I realized that aside from the lack of sum types I really didn&rsquo;t find much missing
from the language. Perhaps improvements to error handling.</p>

<p>Now, my intention here isn&rsquo;t really to sell sum types. They&rsquo;re somewhat controversial for Go, and
there are good arguments on both sides. You can see one discussion on this topic <a href="https://github.com/golang/go/issues/19412">here</a>.
If I were to make a more concrete proposal I&rsquo;d probably try to motivate this in much more depth. But even
I&rsquo;m not very <em>strongly</em> of the opinion that Go needs sum types; I have a slight preference for it.</p>

<p>Instead, I&rsquo;m going to try and sketch this proposal for sum types that has been floating around my
mind for a while. I end up mentioning it often and it&rsquo;s nice to have something to link to. Overall,
I think this &ldquo;fits well&rdquo; with the existing Go language design.</p>

<h2>The proposal</h2>

<p>The essence is pretty straightforward: Extend interfaces to allow for &ldquo;closed interfaces&rdquo;. These are
interfaces that are only implemented for a small list of types.</p>

<p>Writing the <code>Foo</code> sum type above would be:</p>

<pre><code class="go">type Foo interface {
    SomeFunction()
    OtherFunction()
    for string, int
}
</code></pre>

<p>It doesn&rsquo;t even need to have functions defined on it.</p>

<p>The interface functions can only be called if you have an interface object; they are not directly available
on variant types without explicitly casting (<code>Foo("...").SomeFunction()</code>).</p>

<p>(I&rsquo;m not strongly for the <code>for</code> keyword syntax, it&rsquo;s just a suggestion. The core idea is that
you define an interface and you define the types it closes over. Somehow.)</p>

<p>A better example would be an interface for a message-passing system for Raft:</p>

<pre><code class="go">type VoteRequest struct {
    CandidateId uint
    Term uint
    // ...
}

type VoteResponse struct {
    Term uint
    VoteGranted bool
    VoterId uint
}

type AppendRequest struct {
    //...
}

type AppendResponse struct {
    //...
}
// ...
type RaftMessage interface {
    for VoteRequest, VoteResponse, AppendRequest, AppendResponse
}
</code></pre>

<p>Now, you use type switches for dealing with these:</p>

<pre><code class="go">switch value := msg.(type) {
    case VoteRequest:
        if value.Term &lt;= me.Term {
            me.reject_vote(value.CandidateId)
        } else {
            me.accept_vote(value.CandidateId, value.Term)
        }
    case VoteResponse: // ...
    case AppendRequest: // ...
    case AppendResponse: // ...
}
</code></pre>

<p>There is no need for the default case, unless you wish to leave one or more of the cases out.</p>

<p>Ideally, these could be implemented as inline structs instead of using dynamic dispatch. I&rsquo;m not sure
what this entails for the GC design, but I&rsquo;d love to hear thoughts on this.</p>

<p>We also make it possible to add methods to closed interfaces. This is in the spirit of
<a href="https://github.com/golang/go/issues/16254">this proposal</a>, where you allow</p>

<pre><code class="go">func (message RaftMessage) Process(me Me) error {
    // message handling logic
}
</code></pre>

<p>for closed interfaces.</p>

<p>This aligns more with how sum types are written and used in other languages; instead of assuming
that each method will be a <code>switch</code> on the variant, you can write arbitrary code that <em>may</em> <code>switch</code>
on the type but it can also just call other methods. This is really nice because you can write
methods in <em>both</em> ways &ndash; if it&rsquo;s a &ldquo;responsibility of the inner type&rdquo; kind of method, require it in
the interface and delegate it to the individual types. If it&rsquo;s a &ldquo;responsibility of the interface&rdquo;
method, write it as a method on the interface as a whole. I kind of wish Rust had this, because in Rust
you sometimes end up writing things like:</p>

<pre><code class="rust">match foo {
    Foo::Stringy(s) =&gt; s.process(),
    Foo::Numerical(n) =&gt; n.process(),
    // ...
}
</code></pre>

<p>Yes, this would work better as a trait, but then you lose some niceties of Rust enums. With this
proposal Go can have it both ways.</p>

<hr />

<p>Anyway, thoughts? This is a really rough proposal, and I&rsquo;m not sure how receptive other Gophers will be
to this, nor how complex its implementation would be. I don&rsquo;t really intend to submit this as a formal proposal,
but if someone else wants to they are more than welcome to build on this idea.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What Are Tokio and Async IO All About?]]></title>
    <link href="http://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about/"/>
    <updated>2018-01-10T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about</id>
    <content type="html"><![CDATA[<p>The Rust community lately has been focusing a lot on &ldquo;async I/O&rdquo; through the <a href="https://github.com/tokio-rs/">tokio</a>
project. This is pretty great!</p>

<p>But for many in the community who haven&rsquo;t worked with web servers and related things it&rsquo;s pretty
confusing as to what we&rsquo;re trying to achieve there. When this stuff was being discussed around 1.0,
I was pretty lost as well, having never worked with this stuff before.</p>

<p>What&rsquo;s all this Async I/O business about? What are coroutines? Lightweight threads? Futures? How
does this all fit together?</p>

<h2>What problem are we trying to solve?</h2>

<p>One of Rust&rsquo;s key features is &ldquo;fearless concurrency&rdquo;. But the kind of concurrency required for handling a
large amount of I/O bound tasks &ndash; the kind of concurrency found in Go, Elixir, Erlang &ndash; is absent
from Rust.</p>

<p>Let&rsquo;s say you want to build something like a web service. It&rsquo;s going to be handling thousands of
requests at any point in time (known as the &ldquo;<a href="https://en.wikipedia.org/wiki/C10k_problem">c10k</a> problem&rdquo;). In general, the problem we&rsquo;re
considering is having a huge number of I/O bound (usually network I/O) tasks.</p>

<p>&ldquo;Handling N things at once&rdquo; is best done by using threads. But &hellip; <em>thousands</em> of threads? That
sounds a bit much. Threads can be pretty expensive: Each thread needs to allocate a large stack,
setting up a thread involves a bunch of syscalls, and context switching is expensive.</p>

<p>Of course, thousands of threads <em>all doing work</em> at once is not going to work anyway. You only
have a fixed number of cores, and at any one time only one thread will be running on a core.</p>

<p>But for cases like web servers, most of these threads won&rsquo;t be doing work. They&rsquo;ll be waiting on the
network. Most of these threads will either be listening for a request, or waiting for their response
to get sent.</p>

<p>With regular threads, when you perform a blocking I/O operation, the syscall returns control
to the kernel, which won&rsquo;t yield control back, because the I/O operation is probably not finished.
Instead, it will use this as an opportunity to swap in a different thread, and will swap the original
thread back when its I/O operation is finished (i.e. it&rsquo;s &ldquo;unblocked&rdquo;). Without Tokio and friends,
this is how you would handle such things in Rust. Spawn a million threads; let the OS deal with
scheduling based on I/O.</p>

<p>But, as we already discovered, threads don&rsquo;t scale well for things like this<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>.</p>

<p>We need &ldquo;lighter&rdquo; threads.</p>

<h2>Lightweight threading</h2>

<p>I think the best way to understand lightweight threading is to forget about Rust for a moment
and look at a language that does this well, Go.</p>

<p>So instead, Go has lightweight threads, called &ldquo;goroutines&rdquo;. You spawn these with the <code>go</code>
keyword. A web server might do something like this:</p>

<pre><code class="go">listener, err = net.Listen(...)
// handle err
for {
    conn, err := listener.Accept()
    // handle err

    // spawn goroutine:
    go handler(conn)
}
</code></pre>

<p>This is a loop which waits for new TCP connections, and spawns a goroutine with the connection
and the function <code>handler</code>. Each connection will be a new goroutine, and the goroutine will shut down
when <code>handler</code> finishes. In the meantime, the main loop continues executing, because it&rsquo;s running in
a different goroutine.</p>

<p>So if these aren&rsquo;t &ldquo;real&rdquo; (operating system) threads, what&rsquo;s going on?</p>

<p>A goroutine is an example of a &ldquo;lightweight&rdquo; thread. The operating system doesn&rsquo;t know about these,
it sees N threads owned by the Go runtime, and the Go runtime maps M goroutines onto them<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>, swapping
goroutines in and out much like the operating system scheduler. It&rsquo;s able to do this because
Go code is already interruptible for the GC to be able to run, so the scheduler can always ask goroutines
to stop. The scheduler is also aware of I/O, so when a goroutine is waiting on I/O it yields to the scheduler.</p>

<p>Essentialy, a compiled Go function will have a bunch of points scattered throughout it where it
tells the scheduler and GC &ldquo;take over if you want&rdquo; (and also &ldquo;I&rsquo;m waiting on stuff, please take
over&rdquo;).</p>

<p>When a goroutine is swapped on an OS thread, some registers will be saved, and
the program counter will switch to the new goroutine.</p>

<p>But what about its stack? OS threads have a large stack with them, and you kinda need a stack for functions
and stuff to work.</p>

<p>What Go used to do was segmented stacks. The reason a thread needs a large stack is that most
programming languages, including C, expect the stack to be contiguous, and stacks can&rsquo;t just be
&ldquo;reallocated&rdquo; like we do with growable buffers since we expect stack data to stay put so that
pointers to stack data to continue to work. So we reserve all the stack we think we&rsquo;ll ever need
(~8MB), and hope we don&rsquo;t need more.</p>

<p>But the expectation of stacks being contiguous isn&rsquo;t strictly necessary. In Go, stacks are made of tiny
chunks. When a function is called, it checks if there&rsquo;s enough space on the stack for it to run, and if not,
allocates a new chunk of stack and runs on it. So if you have thousands of threads doing a small amount of work,
they&rsquo;ll all get thousands of tiny stacks and it will be fine.</p>

<p>These days, Go actually does something different; it <a href="https://blog.cloudflare.com/how-stacks-are-handled-in-go/">copies stacks</a>. I mentioned that stacks can&rsquo;t
just be &ldquo;reallocated&rdquo; we expect stack data to stay put. But that&rsquo;s not necessarily true &mdash;
because Go has a GC it knows what all the pointers are <em>anyway</em>, and it can rewrite pointers to
stack data on demand.</p>

<p>Either way, Go&rsquo;s rich runtime lets it handle this stuff well. Goroutines are super cheap, and you can spawn
thousands without your computer having problems.</p>

<p>Rust <em>used</em> to support lightweight/&ldquo;green&rdquo; threads (I believe it used segmented stacks). However, Rust cares
a lot about not paying for things you don&rsquo;t use, and this imposes a penalty on all your code even if you
aren&rsquo;t using green threads, and it was removed pre-1.0.</p>

<h2>Async I/O</h2>

<p>A core building block of this is Async I/O. As mentioned in the previous section,
with regular blocking I/O, the moment you request I/O your thread will not be allowed to run
(&ldquo;blocked&rdquo;) until the operation is done. This is perfect when working with OS threads (the OS
scheduler does all the work for you!), but if you have lightweight threads you instead want to
replace the lightweight thread running on the OS thread with a different one.</p>

<p>Instead, you use non-blocking I/O, where the thread queues a request for I/O with the OS and continues
execution. The I/O request is executed at some later point by the kernel. The thread then needs to ask the
OS &ldquo;Is this I/O request ready yet?&rdquo; before looking at the result of the I/O.</p>

<p>Of course, repeatedly asking the OS if it&rsquo;s done can be tedious and consume resources. This is why
there are system calls like <a href="https://en.wikipedia.org/wiki/Epoll"><code>epoll</code></a>. Here, you can bundle together a bunch of unfinished I/O requests,
and then ask the OS to wake up your thread when <em>any</em> of these completes. So you can have a scheduler
thread (a real thread) that swaps out lightweight threads that are waiting on I/O, and when there&rsquo;s nothing
else happening it can itself go to sleep with an <code>epoll</code> call until the OS wakes it up (when one of the I/O
requests completes).</p>

<p>(The exact mechanism involved here is probably more complex)</p>

<p>So, bringing this to Rust, Rust has the <a href="https://github.com/carllerche/mio">mio</a> library, which is a platform-agnostic
wrapper around non-blocking I/O and tools like epoll/kqueue/etc. It&rsquo;s a building block; and while
those used to directly using <code>epoll</code> in C may find it helpful, it doesn&rsquo;t provide a nice programming
model like Go does. But we can get there.</p>

<h2>Futures</h2>

<p>These are another building block. A <a href="https://docs.rs/futures/0.1.17/futures/future/trait.Future.html"><code>Future</code></a> is the promise of eventually having a value
(in fact, in Javascript these are called <code>Promise</code>s).</p>

<p>So for example, you can ask to listen on a network socket, and get a <code>Future</code> back  (actually, a
<code>Stream</code>, which is like a future but for a sequence of values). This <code>Future</code> won&rsquo;t contain the
response <em>yet</em>, but will know when it&rsquo;s ready. You can <code>wait()</code> on a <code>Future</code>, which will block
until you have a result, and you can also <code>poll()</code> it, asking it if it&rsquo;s done yet (it will give you
the result if it is).</p>

<p>Futures can also be chained, so you can do stuff like <code>future.then(|result| process(result))</code>.
The closure passed to <code>then</code> itself can produce another future, so you can chain together
things like I/O operations. With chained futures, <code>poll()</code> is how you make progress; each time
you call it it will move on to the next future provided the existing one is ready.</p>

<p>This is a pretty good abstraction over things like non-blocking I/O.</p>

<p>Chaining futures works much like chaining iterators. Each <code>and_then</code> (or whatever combinator)
call returns a struct wrapping around the inner future, which may contain an additional closure.
Closures themselves carry their references and data with them, so this really ends up being
very similar to a tiny stack!</p>

<h2>🗼 Tokio 🗼</h2>

<p>Tokio&rsquo;s essentially a nice wrapper around mio that uses futures. Tokio has a core
event loop, and you feed it closures that return futures. What it will do is
run all the closures you feed it, use mio to efficiently figure out which futures
are ready to make a step<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>, and make progress on them (by calling <code>poll()</code>).</p>

<p>This actually is already pretty similar to what Go was doing, at a conceptual level.
You have to manually set up the Tokio event loop (the &ldquo;scheduler&rdquo;), but once you do
you can feed it tasks which intermittently do I/O, and the event loop takes
care of swapping over to a new task when one is blocked on I/O. A crucial difference is
that Tokio is single threaded, whereas the Go scheduler can use multiple OS threads
for execution. However, you can offload CPU-critical tasks onto other OS threads and
use channels to coordinate so this isn&rsquo;t that big a deal.</p>

<p>While at a conceptual level this is beginning to shape up to be similar to what we had for Go, code-
wise this doesn&rsquo;t look so pretty. For the following Go code:</p>

<pre><code class="go">// error handling ignored for simplicity

func foo(...) ReturnType {
    data := doIo()
    result := compute(data)
    moreData = doMoreIo(result)
    moreResult := moreCompute(data)
    // ...
    return someFinalResult
}
</code></pre>

<p>The Rust code will look something like</p>

<pre><code class="rust">// error handling ignored for simplicity

fn foo(...) -&gt; Future&lt;ReturnType, ErrorType&gt; {
    do_io().and_then(|data| do_more_io(compute(data)))
          .and_then(|more_data| do_even_more_io(more_compute(more_data)))
    // ......
}
</code></pre>

<p>Not pretty. <a href="http://alexcrichton.com/futures-rs/futures/future/fn.loop_fn.html#examples">The code gets worse if you introduce branches and loops</a>. The problem is that in Go we
got the interruption points for free, but in Rust we have to encode this by chaining up combinators
into a kind of state machine. Ew.</p>

<h2>Generators and async/await</h2>

<p>This is where generators (also called coroutines) come in.</p>

<p><a href="https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html">Generators</a> are an experimental feature in Rust. Here&rsquo;s an example:</p>

<pre><code class="rust">let mut generator = || {
    let i = 0;
    loop {
        yield i;
        i += 1;
    }
};
assert_eq!(generator.resume(), GeneratorState::Yielded(0));
assert_eq!(generator.resume(), GeneratorState::Yielded(1));
assert_eq!(generator.resume(), GeneratorState::Yielded(2));
</code></pre>

<p>Functions are things which execute a task and return once. On the other hand, generators
return multiple times; they pause execution to &ldquo;yield&rdquo; some data, and can be resumed
at which point they will run until the next yield. While my example doesn&rsquo;t show this, generators
can also finish executing like regular functions.</p>

<p>Closures in Rust are
<a href="http://huonw.github.io/blog/2015/05/finding-closure-in-rust/">sugar for a struct containing captured data, plus an implementation of one of the <code>Fn</code> traits to make it callable</a>.</p>

<p>Generators are similar, except they implement the <code>Generator</code> trait<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>, and usually store an enum representing various states.</p>

<p>The <a href="https://doc.rust-lang.org/nightly/unstable-book/language-features/generators.html#generators-as-state-machines">unstable book</a> has some examples on what the generator state machine enum will look like.</p>

<p>This is much closer to what we were looking for! Now our code can look like this:</p>

<pre><code class="rust">fn foo(...) -&gt; Future&lt;ReturnType, ErrorType&gt; {
    let generator = || {
        let mut future = do_io();
        let data;
        loop {
            // poll the future, yielding each time it fails,
            // but if it succeeds then move on
            match future.poll() {
                Ok(Async::Ready(d)) =&gt; { data = d; break },
                Ok(Async::NotReady(d)) =&gt; (),
                Err(..) =&gt; ...
            };
            yield future.polling_info();
        }
        let result = compute(data);
        // do the same thing for `doMoreIo()`, etc
    }

    futurify(generator)
}
</code></pre>

<p>where <code>futurify</code> is a function that takes a generator and returns a future which on
each <code>poll</code> call will <code>resume()</code> the generator, and return <code>NotReady</code> until the generator
finishes executing.</p>

<p>But wait, this is even <em>more</em> ugly! What was the point of converting our relatively
clean callback-chaining code into this mess?</p>

<p>Well, if you look at it, this code now looks <em>linear</em>. We&rsquo;ve converted our callback
code to the same linear flow as the Go code, however it has this weird loop-yield boilerplate
and the <code>futurify</code> function and is overall not very neat.</p>

<p>And that&rsquo;s where <a href="https://github.com/alexcrichton/futures-await">futures-await</a> comes in. <code>futures-await</code> is a procedural macro that
does the last-mile work of packaging away this boilerplate. It essentially lets you write
the above function as</p>

<pre><code class="rust">#[async]
fn foo(...) -&gt; Result&lt;ReturnType, ErrorType&gt; {
    let data = await!(do_io());
    let result = compute(data);
    let more_data = await!(do_more_io());
    // ....
</code></pre>

<p>Nice and clean. Almost as clean as the Go code, just that we have explicit <code>await!()</code> calls. These
await calls are basically providing the same function as the interruption points that Go code
gets implicitly.</p>

<p>And, of course, since it&rsquo;s using a generator under the hood, you can loop and branch and do whatever
else you want as normal, and the code will still be clean.</p>

<h2>Tying it together</h2>

<p>So, in Rust, futures can be chained together to provide a lightweight stack-like system. With async/await,
you can neatly write these future chains, and <code>await</code> provides explicit interruption points on each I/O operation.
Tokio provides an event loop &ldquo;scheduler&rdquo; abstraction, which you can feed async functions to, and under the hood it
uses mio to abstract over low level non-blocking I/O primitives.</p>

<p>These are components which can be used independently &mdash; you can use tokio with futures without
using async/await. You can use async/await without using Tokio. For example, I think this would be
useful for Servo&rsquo;s networking stack. It doesn&rsquo;t need to do <em>much</em> parallel I/O (not at the order
of thousands of threads), so it can just use multiplexed OS threads. However, we&rsquo;d still want
to pool threads and pipeline data well, and async/await would help here.</p>

<p>Put together, all these components get something almost as clean as the Go stuff, with a little more
explicit boilerplate. Because generators (and thus async/await) play nice with the borrow checker
(they&rsquo;re just enum state machines under the hood), Rust&rsquo;s safety guarantees are all still in play,
and we get to have &ldquo;fearless concurrency&rdquo; for programs having a huge quantity of I/O bound tasks!</p>

<p><em>Thanks to Arshia Mufti, Steve Klabnik, Zaki Manian, and Kyle Huey for reviewing drafts of this post</em></p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Note that this isn&rsquo;t necessarily true for <em>all</em> network server applications. For example, Apache uses OS threads. OS threads are often the best tool for the job.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>Lightweight threading is also often called M:N threading (also &ldquo;green threading&rdquo;)<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>In general future combinators aren&rsquo;t really aware of tokio or even I/O, so there&rsquo;s no easy way to ask a combinator &ldquo;hey, what I/O operation are you waiting for?&rdquo;. Instead, with Tokio you use special I/O primitives that still provide futures but also register themselves with the scheduler in thread local state. This way when a future is waiting for I/O, Tokio can check what the recentmost I/O operation was, and associate it with that future so that it can wake up that future again when <code>epoll</code> tells it that that I/O operation is ready.<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>The <code>Generator</code> trait has a <code>resume()</code> function which you can call multiple times, and each time it will return any yielded data or tell you that the generator has finished running.<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rust in 2018]]></title>
    <link href="http://manishearth.github.io/blog/2018/01/10/rust-in-2018/"/>
    <updated>2018-01-10T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2018/01/10/rust-in-2018</id>
    <content type="html"><![CDATA[<p>A week ago <a href="https://blog.rust-lang.org/2018/01/03/new-years-rust-a-call-for-community-blogposts.html">we put out a call for blog posts for what folks think Rust should do in 2018</a>.</p>

<p>This is mine.</p>

<h2>Overall focus</h2>

<p>I think 2017 was a great year for Rust. Near the beginning of the year, after custom derive
and a bunch of things stabilized, I had a strong feeling that Rust was &ldquo;complete&rdquo;. Not really &ldquo;finished&rdquo;,
there&rsquo;s still tons of stuff to improve, but this was the first time stable Rust was the language
I wanted it to be, and was something I could recommend for most kinds of work without reservations.</p>

<p>I think this is a good signal to wind down the frightening pace of new features Rust has been getting.
And that happened! We had the impl period, which took some time to focus on <em>getting things done</em> before
proposing new things. And Rust is feeling more polished than ever.</p>

<p>Like <a href="https://www.ncameron.org/blog/rust-2018/">Nick</a>, I feel like 2018 should be boring. I feel like we should focus on polishing what
we have, implementing all the things, and improving our approachability as a language.</p>

<p>Basically, I want to see this as an extended impl period.</p>

<p>This doesn&rsquo;t mean I&rsquo;m looking for a moratorium on RFCs, really. Hell, in the past few days I&rsquo;ve posted
one pre-pre-RFC<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, one pre-RFC, and one RFC (from the pre-RFC). I&rsquo;m mostly looking for <em>prioritizing</em> impl
work over designing new things, but still having <em>some</em> focus on design.</p>

<h2>Language</h2>

<p>I think Rust still has some &ldquo;missing bits&rdquo; which make it hard to justify for some use cases. Rust&rsquo;s
async story is being fleshed out. We don&rsquo;t yet have stable SIMD or stable inline ASM. The microcontroller
story is kinda iffy. RLS/clippy need nightly. I&rsquo;d like to see these crystallize and stabilize this year.</p>

<p>I think this year we need to continue to take a critical look at Rust&rsquo;s ergonomics. Last year the
ergonomics initiative was really good for Rust, and I&rsquo;d like to see more of that. This is kind of at
odds with my &ldquo;focus on polishing Rust&rdquo; statement, but fixing ergonomics is not just new features. It&rsquo;s
also about figuring out barriers in Rust, polishing mental models, improving docs/diagnostics, and in
general figuring out how to best present Rust&rsquo;s features. Starting dialogues about confusing bits of
the language and figuring out the best mental model to present them with is something we should
continue doing. Sometimes this may need new features, indeed, but not always. We must continue
to take a critical look at how our language presents itself to newcomers.</p>

<h2>Community</h2>

<p>I&rsquo;d like to see a stronger focus on mentoring. Mentoring on rustc, mentoring on major libraries, mentoring on
Rust tooling, mentoring everywhere. This includes not just the mentors, but the associated infrastructure &ndash;
contribution docs, sites like <a href="http://starters.servo.org/">servo-starters</a> and <a href="https://www.rustaceans.org/findwork">findwork</a>, and similar tooling.</p>

<p>I&rsquo;m also hoping for more companies to invest back into Rust. This year <a href="http://buoyant.io/">Buoyant</a> became pretty well
known within the community, and many of their employees are paid to work on various important parts
of the Rust ecosystem. There are also multiple consulting groups that contribute to the ecosystem.
It&rsquo;s nice to see that &ldquo;paid to work on Rust&rdquo; is no longer limited to Mozilla, and this is crucial
for the health of the language. I hope this trend continues.</p>

<p>Finally, I want to see more companies <em>talk</em> about Rust. Success stories are really nice to hear.
I&rsquo;ve heard many amazing success stories this year, but a lot of them are things which can&rsquo;t be shared.</p>

<h2>Governance</h2>

<p>Last year we started seeing the limits of the RFC process. Large RFCs were stressful for both the RFC authors
and participating community members, and rather opaque for newer community members wishing to participate.
Alternative models have been discussed; I&rsquo;d like to see more movement on this front.</p>

<p>I&rsquo;d also like to grow the moderation team; it is currently rather small and doesn&rsquo;t have the capacity to handle
incidents in a timely fashion.</p>

<h2>Docs / Learning</h2>

<p>I&rsquo;d like to see a focus on improving Rust for folks who learn the language by <em>trying things</em> over reading books <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>&nbsp;<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>.</p>

<p>This means better diagnostics, better alternative resources like rustbyexample, etc. Improving mentorship helps here
as well.</p>

<p>Of course, I&rsquo;d like to see our normal docs work continue to happen.</p>

<hr />

<p>I&rsquo;m overall really excited for 2018. I think we&rsquo;re doing great on most fronts so far, and if we
maintain the momentum we&rsquo;ll have an even-more-awesome Rust by the end of this year!</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>This isn&rsquo;t a &ldquo;pre rfc&rdquo; because I&rsquo;ve written it as a much looser sketch of the problem and a solution<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>There is literally no programming language I&rsquo;ve personally learned through a book or formal teaching. I&rsquo;ve often read books after I know a language because it&rsquo;s fun and instructive, but it&rsquo;s always started out as &ldquo;learn extreme basics&rdquo; followed by &ldquo;look at existing code, tweak stuff, and write your own code&rdquo;.<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>Back in <em>my</em> day Rust didn&rsquo;t have a book, just this tiny thing called &ldquo;The Tutorial&rdquo;. <em>grouches incessantly</em><a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Undefined vs Unsafe in Rust]]></title>
    <link href="http://manishearth.github.io/blog/2017/12/24/undefined-vs-unsafe-in-rust/"/>
    <updated>2017-12-24T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2017/12/24/undefined-vs-unsafe-in-rust</id>
    <content type="html"><![CDATA[<p>Recently Julia Evans wrote an <a href="https://jvns.ca/blog/2017/12/23/segfault-debugging/">excellent post</a> about debugging a segfault in Rust. (Go read it, it&rsquo;s good)</p>

<p>One thing it mentioned was</p>

<blockquote><p>I think “undefined” and “unsafe” are considered to be synonyms.</p></blockquote>

<p>This is &hellip; incorrect. However, we in the Rust community have never really explicitly outlined the
distinction, so that confusion is on us! This blog post is an attempt to clarify the difference of
terminology as used within the Rust community. It&rsquo;s a very useful but subtle distinction and I feel we&rsquo;d be
able to talk about safety more expressively if this was well known.</p>

<h2>Unsafe means two things in Rust, yay</h2>

<p>So, first off, the waters are a bit muddied by the fact that Rust uses <code>unsafe</code> to both mean &ldquo;within
an <code>unsafe {}</code> block&rdquo; block and &ldquo;something Bad is happening here&rdquo;. It&rsquo;s possible to have safe code
within an <code>unsafe</code> block; indeed this is the <em>primary function</em> of an <code>unsafe</code> block. Somewhat
counterintutively, the <code>unsafe</code> block&rsquo;s purpose is to actually tell the compiler &ldquo;I know you don&rsquo;t
like this code but trust me, it&rsquo;s safe!&rdquo; (where &ldquo;safe&rdquo; is the negation of the <em>second</em> meaning of &ldquo;unsafe&rdquo;,
i.e. &ldquo;something Bad is not happening here&rdquo;).</p>

<p>Similarly, we use &ldquo;safe code&rdquo; to mean &ldquo;code not using <code>unsafe{}</code> blocks&rdquo; but also &ldquo;code that is not unsafe&rdquo;,
i.e. &ldquo;code where nothing bad happens&rdquo;.</p>

<p>This blog post is primarily about the &ldquo;something bad is happening here&rdquo; meaning of &ldquo;unsafe&rdquo;. When referring
to the other kind I&rsquo;ll specifically say &ldquo;code within <code>unsafe</code> blocks&rdquo; or something like that.</p>

<h2>Undefined behavior</h2>

<p>In languages like C, C++, and Rust, undefined behavior is when you reach a point where
the compiler is allowed to do anything with your code. This is distinct from implementation-defined
behavior, where usually a given compiler/library will do a deterministic thing, however they have some
freedom from the spec in deciding what that thing is.</p>

<p>Undefined behavior can be pretty scary. This is usually because in practice it causes problems when
the compiler assumes &ldquo;X won&rsquo;t happen because it is undefined behavior&rdquo;, and X ends up happening,
breaking the assumptions. In some cases this does nothing dangerous, but often the compiler will
end up doing wacky things to your code. Dereferencing a null pointer will <em>sometimes</em> cause segfaults
(which is the compiler generating code that actually dereferences the pointer, making the kernel
complain), but sometimes it will be optimized in a way that assumes it won&rsquo;t and moves around code
such that you have major problems.</p>

<p>Undefined behavior is a global property, based on how your code is <em>used</em>. The following function
in C++ or Rust may or may not exhibit undefined behavior, based on how it gets used:</p>

<pre><code class="cpp">int deref(int* x) {
    return *x;
}
</code></pre>

<pre><code class="rust">// do not try this at home
fn deref(x: *mut u32) -&gt; u32 {
    unsafe { *x }
}
</code></pre>

<p>As long as you always call it with a valid pointer to an integer, there is no undefined behavior
involved.</p>

<p>But in either language, if you use it with some pointer conjured out of thin air (or, like <code>0x01</code>), that&rsquo;s
probably undefined behavior.</p>

<p>As it stands, UB is a property of the entire program and its execution. Sometimes you may have snippets of code
that will always exhibit undefined behavior regardless of how they are called, but in general UB
is a global property.</p>

<h2>Unsafe behavior</h2>

<p>Rust&rsquo;s concept of &ldquo;unsafe behavior&rdquo; (I&rsquo;m coining this term because &ldquo;unsafety&rdquo; and &ldquo;unsafe code&rdquo; can
be a bit confusing) is far more scoped. Here, <code>fn deref</code> <em>is</em> &ldquo;unsafe&rdquo;<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, even if you <em>always</em>
call it with a valid pointer. The reason it is still unsafe is because it&rsquo;s possible to trigger UB by only
changing the &ldquo;safe&rdquo; caller code. I.e. &ldquo;changes to code outside unsafe blocks can trigger UB if they include
calls to this function&rdquo;.</p>

<p>Basically, in Rust a bit of code is &ldquo;safe&rdquo; if it cannot exhibit undefined behavior under all circumstances of
that code being used. The following code exhibits &ldquo;safe behavior&rdquo;:</p>

<pre><code class="rust">unsafe {
    let x = 1;
    let raw = &amp;x as *const u32;
    println!("{}", *raw);
}
</code></pre>

<p>We dereferenced a raw pointer, but we knew it was valid. Of course, actual <code>unsafe</code> blocks will
usually be &ldquo;actually totally safe&rdquo; for less obvious reasons, and part of this is because
<a href="https://doc.rust-lang.org/nomicon/working-with-unsafe.html#working-with-unsafe"><code>unsafe</code> blocks sometimes can pollute the entire module</a>.</p>

<p>Basically, &ldquo;safe&rdquo; in Rust is a more local property. Code isn&rsquo;t safe just because you only use it in
a way that doesn&rsquo;t trigger UB, it is safe because there is literally <em>no way to use it such that it
will do so</em>. No way to do so without using <code>unsafe</code> blocks, that is<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>.</p>

<p>This is a distinction that&rsquo;s <em>possible</em> to draw in Rust because it gives us the ability
to compartmentalize safety. Trying to apply this definition to C++ is problematic; you can
ask &ldquo;is <code>std::unique_ptr&lt;T&gt;</code> safe?&rdquo;, but you can <em>always</em> use it within code in a way that you trigger
undefined behavior, because C++ does not have the tools for compartmentalizing safety. The distinction
between &ldquo;code which doesn&rsquo;t need to worry about safety&rdquo; and &ldquo;code which does need to worry about safety&rdquo;
exists in Rust in the form of &ldquo;code outside of <code>unsafe {}</code>&rdquo; and &ldquo;code within <code>unsafe {}</code>&rdquo;, whereas in
C++ it&rsquo;s a lot fuzzier and based on expectations (and documentation/the spec).</p>

<p>So C++&rsquo;s <code>std::unique_ptr&lt;T&gt;</code> is &ldquo;safe&rdquo; in the sense that it does what you expect but
if you use it in a way counter to how it&rsquo;s <em>supposed</em> to be used (constructing one from an invalid pointer, for example)
it can blow up. This is still a useful sense of safety, and is how one regularly reasons about safety in C++. However it&rsquo;s not
the same sense of the term as used in Rust, which can be a bit more formal about what the expectations
actually are.</p>

<p>So <code>unsafe</code> in Rust is a strictly more general concept &ndash; all code exhibiting undefined behavior in Rust is also &ldquo;unsafe&rdquo;,
however not all &ldquo;unsafe&rdquo; code in Rust exhibits undefined behavior as written in the current program.</p>

<p>Rust furthermore attempts to guarantee that you will not trigger undefined behavior if you do not use <code>unsafe {}</code> blocks.
This of course depends on the correctness of the compiler (it has bugs) and of the libraries you use (they may also have bugs)
but this compartmentalization gets you most of the way there in having UB-free programs.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Once again in we have a slight difference between an &ldquo;<code>unsafe fn</code>&rdquo;, i.e. a function that needs an <code>unsafe</code> block to call and probably is unsafe, and an &ldquo;unsafe function&rdquo;, a function that exhibits unsafe behavior.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>This caveat and the confusing dual-usage of the term &ldquo;safe&rdquo; lead to the rather tautological-sounding sentence &ldquo;Safe Rust code is Rust code that cannot cause undefined behavior when used in safe Rust code&rdquo;<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Teaching Programming: Proactive vs Reactive]]></title>
    <link href="http://manishearth.github.io/blog/2017/05/19/teaching-programming-proactive-vs-reactive/"/>
    <updated>2017-05-19T00:00:00+00:00</updated>
    <id>http://manishearth.github.io/blog/2017/05/19/teaching-programming-proactive-vs-reactive</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve been thinking about this a lot these days. In part because of <a href="https://github.com/Manishearth/rust-clippy/issues/1737">an idea I had</a>
but also due to <a href="https://twitter.com/sehurlburt/status/863829482645340160">this twitter discussion</a>.</p>

<p>When teaching most things, there are two non-mutually-exclusive ways of approaching the problem. One
is &ldquo;proactive&rdquo;<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, which is where the teacher decides a learning path beforehand, and executes it. The
other is &ldquo;reactive&rdquo;, where the teacher reacts to the student trying things out and dynamically
tailors the teaching experience.</p>

<p>Most in-person teaching experiences are a mix of both. Planning beforehand is very important whilst teaching,
but tailoring the experience to the student&rsquo;s reception of the things being taught is important too.</p>

<p>In person, you <em>can</em> mix these two, and in doing so you get a &ldquo;best of both worlds&rdquo; situation. Yay!</p>

<p>But &hellip; we don&rsquo;t really learn much programming in a classroom setup.
Sure, some folks learn the basics in college for a few years, but everything
they learn after that isn&rsquo;t in a classroom situation where this can work<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>.
I&rsquo;m an autodidact,
and while I have taken a few programming courses for random interesting things, I&rsquo;ve taught myself most of what I know
using various sources. I care a lot about improving the situation here.</p>

<p>With self-driven learning we have a similar divide. The &ldquo;proactive&rdquo; model corresponds to reading books
and docs. Various people have proactively put forward a path for learning in the form of a book
or tutorial. It&rsquo;s up to you to pick one, and follow it.</p>

<p>The &ldquo;reactive&rdquo; model is not so well-developed. In the context of self-driven learning in programming,
it&rsquo;s basically &ldquo;do things, make mistakes, hope that Google/Stackoverflow help&rdquo;. It&rsquo;s how
a lot of people learn programming; and it&rsquo;s how I prefer to learn programming.</p>

<p>It&rsquo;s very nice to be able to &ldquo;learn along the way&rdquo;. While this is a long and arduous process,
involving many false starts and a lack of a sense of progress, it can be worth it in terms of
the kind of experience this gets you.</p>

<p>But as I mentioned, this isn&rsquo;t as well-developed. With the proactive approach, there still
is a teacher &ndash; the author of the book! That teacher may not be able to respond in real time,
but they&rsquo;re able to set forth a path for you to work through.</p>

<p>On the other hand, with the &ldquo;reactive&rdquo; approach, there is no teacher. Sure, there are
Random Answers on the Internet, which are great, but they don&rsquo;t form a coherent story.
Neither can you really be your own teacher for a topic you do not understand.</p>

<p>Yet plenty of folks do this. Plenty of folks approach things like learning a new language by reading
at most two pages of docs and then just diving straight in and trying stuff out. The only language I
have not done this for is the first language I learned<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>&nbsp;<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>.</p>

<p>I think it&rsquo;s unfortunate that folks who prefer this approach don&rsquo;t get the benefit of a teacher.
In the reactive approach, teachers can still tell you what you&rsquo;re doing wrong and steer you away from
tarpits of misunderstanding. They can get you immediate answers and guidance. When we look
for answers on stackoverflow, we get some of this, but it also involves a lot of pattern-matching
on the part of the student, and we end up with a bad facsimile of what a teacher can do for you.</p>

<p>But it&rsquo;s possible to construct a better teacher for this!</p>

<p>In fact, examples of this exist in the wild already!</p>

<p>The Elm compiler is my favorite example of this. <a href="http://elm-lang.org/blog/compilers-as-assistants">It has amazing error messages</a></p>

<p><img class="center" src="/images/post/elm-error.png">
<img class="center" src="/images/post/elm-error2.png"></p>

<p>The error messages tell you what you did wrong, sometimes suggest fixes, and help
correct potential misunderstandings.</p>

<p>Rust does this too. Many compilers do. (Elm is exceptionally good at it)</p>

<p><img class="center" src="/images/post/rust-error.png" width="700"></p>

<p>One thing I particularly like about Rust is that from that error you can
try <code>rustc --explain E0373</code> and get a terminal-friendly version
of <a href="https://doc.rust-lang.org/nightly/error-index.html#E0373">this help text</a>.</p>

<p>Anyway, diagnostics basically provide a reactive component to learning programming. I&rsquo;ve cared about
diagnostics in Rust for a long time, and I often remind folks that many things taught through the
docs can/should be taught through diagnostics too. Especially because diagnostics are a kind of soapbox
for compiler writers &mdash; you can&rsquo;t guarantee that your docs will be read, but you can guarantee
that your error messages will. These days, while I don&rsquo;t have much time to work on stuff myself I&rsquo;m
very happy to mentor others working on improving diagnostics in Rust.</p>

<p>Only recently did I realize <em>why</em> I care about them so much &ndash; they cater exactly to my approach
to learning programming languages! If I&rsquo;m not going to read the docs when I get started and try the
reactive approach, having help from the compiler is invaluable.</p>

<p>I think this space is relatively unexplored. Elm might have the best diagnostics out there,
and as diagnostics (helping all users of a language &ndash; new and experienced), they&rsquo;re great,
but as a teaching tool for newcomers; they still have a long way to go. Of course, compilers
like Rust are even further behind.</p>

<p>One thing I&rsquo;d like to experiment with is a first-class tool for reactive teaching. In a sense,
<a href="https://github.com/Manishearth/rust-clippy">clippy</a> is already something like this. Clippy looks out for antipatterns, and tries to help
teach. But it also does many other things, and not all are teaching moments are antipatterns.</p>

<p>For example, in C, this isn&rsquo;t necessarily an antipattern:</p>

<pre><code class="c">struct thingy *result;
if (result = do_the_thing()) {
    frob(*result)
}
</code></pre>

<p>Many C codebases use <code>if (foo = bar())</code>. It is a potential footgun if you confuse it with <code>==</code>,
but there&rsquo;s no way to be sure. Many compilers now have a warning for this that you can silence by
doubling the parentheses, though.</p>

<p>In Rust, this isn&rsquo;t an antipattern either:</p>

<pre><code class="rust">fn add_one(mut x: u8) {
    x += 1;
}

let num = 0;
add_one(num);
// num is still 0
</code></pre>

<p>For someone new to Rust, they may feel that the way to have a function mutate arguments (like <code>num</code>) passed to it
is to use something like <code>mut x: u8</code>. What this actually does is copies <code>num</code> (because <code>u8</code> is a <code>Copy</code> type),
and allows you to mutate the copy within the scope of the function. The right way to make a function that
mutates arguments passed to it by-reference would be to do something like <code>fn add_one(x: &amp;mut u8)</code>.
If you try the <code>mut x</code> thing for non-Copy values, you&rsquo;d get a &ldquo;reading out of moved value&rdquo; error
when you try to access <code>num</code> after calling <code>add_one</code>. This would help you figure out what you did wrong,
and potentially that error could detect this situation and provide more specific help.</p>

<p>But for <code>Copy</code> types, this will just compile. And it&rsquo;s not an antipattern &ndash; the way this works
makes complete sense in the context of how Rust variables work, and is something that you do need
to use at times.</p>

<p>So we can&rsquo;t even warn on this. Perhaps in &ldquo;pedantic clippy&rdquo; mode, but really, it&rsquo;s not
a pattern we want to discourage. (At least in the C example that pattern is one
that many people prefer to forbid from their codebase)</p>

<p>But it would be nice if we could tell a learning programmer &ldquo;hey, btw, this is what this syntax
means, are you sure you want to do this?&rdquo;. With explanations and the ability to dismiss the error.</p>

<p>In fact, you don&rsquo;t even need to restrict this to potential footguns!</p>

<p>You can detect various things the learner is trying to do. Are they probably mixing up <code>String</code>
and <code>&amp;str</code>? Help them! Are they writing a trait? Give a little tooltip explaining the feature.</p>

<p>This is beginning to remind me of the original &ldquo;office assistant&rdquo; <a href="https://en.wikipedia.org/wiki/Office_Assistant">Clippy</a>, which was super annoying.
But an opt-in tool or IDE feature which gives helpful suggestions could still be nice, especially
if you can strike a balance between being so dense it is annoying and so sparse it is useless.</p>

<p>It also reminds me of well-designed tutorial modes in games. Some games have a tutorial mode that guides you
through a set path of doing things. Other games, however, have a tutorial mode that will give you hints even
if you stray off the beaten path. <a href="https://twitter.com/mgattozzi">Michael</a> tells me that <a href="http://store.steampowered.com/app/480490/Prey/">Prey</a> is
a recent example of such a game.</p>

<p>This really feels like it fits the &ldquo;reactive&rdquo; model I prefer. The student gets to mold their own
journey, but gets enough helpful hints and nudges from the &ldquo;teacher&rdquo; (the tool) so that they
don&rsquo;t end up wasting too much time and can make informed decisions on how to proceed learning.</p>

<p>Now, rust-clippy isn&rsquo;t exactly the place for this kind of tool. This tool needs the ability to globally
&ldquo;silence&rdquo; a hint once you&rsquo;ve learned it. rust-clippy is a linter, and while you can silence lints in
your code, you can&rsquo;t silence them globally for the current user. Nor does that really make sense.</p>

<p>But rust-clippy does have the infrastructure for writing stuff like this, so it&rsquo;s an ideal prototyping
point. I&rsquo;ve filed <a href="https://github.com/Manishearth/rust-clippy/issues/1737">this issue</a> to discuss this topic.</p>

<p>Ultimately, I&rsquo;d love to see this as an IDE feature.</p>

<p>I&rsquo;d also like to see more experimentation in the department of &ldquo;reactive&rdquo; teaching &mdash; not just tools like this.</p>

<p>Thoughts? Ideas? Let me know!</p>

<p><em>thanks to Andre (llogiq) and Michael Gattozzi for reviewing this</em></p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>This is how I&rsquo;m using these terms. There seems to be precedent in pedagogy for the proactive/reactive classification, but it might not be exactly the same as the way I&rsquo;m using it.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>This is true for everything, but I&rsquo;m focusing on programming (in particular programming <em>languages</em>) here.<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>And when I learned Rust, it only <em>had</em> two pages of docs, aka &ldquo;The Tutorial&rdquo;. Good times.<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>I do eventually get around to doing a full read of the docs or a book but this is after I&rsquo;m already able to write nontrivial things in the language, and it takes a lot of time to get there.<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
</feed>
